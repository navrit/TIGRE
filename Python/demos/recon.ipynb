{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Windows: Open Anaconda prompt\n",
    "conda create --name tigre_env -c anaconda -c ccpi -c conda-forge  python tigre simpleitk ipykernel opencv astropy tomopy nibabel scikit-image scikit-learn scipy tqdm scikit-learn-intelex jupyter ipywidgets\n",
    "conda activate tigre_env\n",
    "\n",
    "conda list --export > conda-package-list.txt\n",
    "conda create -n tigre_env --file conda-package-list.txt\n",
    "'''\n",
    "\n",
    "import json\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import tomopy\n",
    "from astropy.convolution import Gaussian2DKernel, interpolate_replace_nans\n",
    "from PIL import Image\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.signal import medfilt2d\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from tqdm import trange, tqdm\n",
    "# from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import tigre\n",
    "import tigre.algorithms as algs\n",
    "from tigre.utilities.geometry import Geometry\n",
    "\n",
    "import filereader\n",
    "\n",
    "kernel = Gaussian2DKernel(x_stddev=2)\n",
    "\n",
    "# make a list of globals for the recnstruction setting, and log them in a json file\n",
    "gFillgap = True\n",
    "gMedianfilter = False\n",
    "gBadPixelCorrection = True\n",
    "gReconVoxels = (600, 600, 600)  # number of voxels              (vx)\n",
    "gReconSize = (15, 15, 15)      # total size of the image       (mm)\n",
    "# gDistSourceDetect = 192.57   # Unused variable - this needs to be checked properly\n",
    "# gDistSourceObject = 43.74    # Unused variable - this needs to be checked properly\n",
    "\n",
    "\n",
    "\n",
    "class ConeGeometryJasper(Geometry):\n",
    "\n",
    "    def __init__(self, high_quality=True, nVoxel = None):\n",
    "\n",
    "        Geometry.__init__(self)\n",
    "        if high_quality:\n",
    "            # VARIABLE                                          DESCRIPTION                    UNITS\n",
    "            # -------------------------------------------------------------------------------------\n",
    "            self.DSD = 192.57                                      # Distance Source Detector      (mm)\n",
    "            self.DSO = self.DSD-43.74                                       # Distance Source Origin        (mm)\n",
    "            # Detector parameters\n",
    "            self.nDetector = np.array((512, 512))               # number of pixels              (px)\n",
    "            self.dDetector = np.array((0.055, 0.055))               # size of each pixel            (mm)\n",
    "            self.sDetector = self.nDetector * self.dDetector    # total size of the detector    (mm)\n",
    "            # Image parameters\n",
    "            self.nVoxel = np.array((512, 512, 512))             # number of voxels              (vx)\n",
    "            self.sVoxel = np.array((28.16, 28.16, 28.16))          # total size of the image       (mm)\n",
    "            self.dVoxel = self.sVoxel/self.nVoxel               # size of each voxel            (mm)\n",
    "            # Offsets\n",
    "#             self.offOrigin = np.array((0,2.53,0))                # Offset of image from origin   (mm)\n",
    "            self.offOrigin = np.array((0,0,0))                # Offset of image from origin   (mm)\n",
    "            self.offDetector = np.array((0, 0))                 # Offset of Detector            (mm)\n",
    "#             self.offDetector = np.array((0, -2.4684))                 # Offset of Detector            (mm)\n",
    "            self.rotDetector = np.array((0,0,0))\n",
    "\n",
    "            # Auxiliary\n",
    "            self.accuracy = 0.5                                 # Accuracy of FWD proj          (vx/sample)\n",
    "            # Mode\n",
    "            self.mode = 'cone'                                  # parallel, cone                ...\n",
    "            self.filter = None\n",
    "        else:\n",
    "            self.DSD = 192.57                                      # Distance Source Detector      (mm)\n",
    "            self.DSO = self.DSD -  43.74                                       # Distance Source Origin        (mm)\n",
    "            # Detector parameters\n",
    "#             self.nDetector = np.array((256, 256))               # number of pixels              (px)\n",
    "            self.nDetector = np.array((11, 512))               # number of pixels              (px)\n",
    "            self.dDetector = np.array((0.055, 0.055))               # size of each pixel            (mm)\n",
    "            self.sDetector = self.nDetector * self.dDetector    # total size of the detector    (mm)\n",
    "            # Image parameters\n",
    "            self.nVoxel = np.array((1, 512, 512))             # number of voxels              (vx)\n",
    "            self.sVoxel = np.array((0.05, 25.6, 25.6))          # total size of the image       (mm)\n",
    "            self.dVoxel = self.sVoxel/self.nVoxel               # size of each voxel            (mm)\n",
    "            # Offsets\n",
    "#             self.offOrigin = np.array((0,2.53,0))                # Offset of image from origin   (mm)\n",
    "            self.offOrigin = np.array((0,0,0))                # Offset of image from origin   (mm)\n",
    "            self.offDetector = np.array((0,0))                 # Offset of Detector            (mm)\n",
    "            self.rotDetector = np.array((0,0,0))\n",
    "\n",
    "            # Auxiliary\n",
    "            self.accuracy = 0.5                                 # Accuracy of FWD proj          (vx/sample)\n",
    "            # Mode\n",
    "            self.mode = 'cone'                                  # parallel, cone                ...\n",
    "            self.filter = None\n",
    "        if nVoxel is not None:\n",
    "            # VARIABLE                                          DESCRIPTION                    UNITS\n",
    "            # -------------------------------------------------------------------------------------\n",
    "            self.DSD = 1536                                     # Distance Source Detector      (mm)\n",
    "            self.DSO = 1000                                     # Distance Source Origin        (mm)\n",
    "                                                                # Detector parameters\n",
    "            self.nDetector = np.array((nVoxel[1],\n",
    "                                       nVoxel[2])\n",
    "                                                                ) # (V,U) number of pixels        (px)\n",
    "            self.dDetector = np.array([0.8, 0.8])               # size of each pixel            (mm)\n",
    "            self.sDetector = self.dDetector * self.nDetector    # total size of the detector    (mm)\n",
    "                                                                # Image parameters\n",
    "            self.nVoxel = np.array((nVoxel))                    # number of voxels              (vx)\n",
    "            self.sVoxel = np.array((256, 256, 256))             # total size of the image       (mm)\n",
    "            self.dVoxel = self.sVoxel / self.nVoxel             # size of each voxel            (mm)\n",
    "            # Offsets\n",
    "            self.offOrigin = np.array((0, 0, 0))                # Offset of image from origin   (mm)\n",
    "            self.offDetector = np.array((0, 0))                 # Offset of Detector            (mm)\n",
    "            self.rotDetector = np.array((0, 0, 0))\n",
    "            # Auxiliary\n",
    "            self.accuracy = 0.5                                 # Accuracy of FWD proj          (vx/sample)\n",
    "            # Mode\n",
    "            self.mode = 'cone'                                  # parallel, cone\n",
    "\n",
    "\n",
    "def solve_for_y(poly_coeffs, y):\n",
    "    pc = poly_coeffs.copy()\n",
    "    pc[-1] -= y\n",
    "    return np.roots(pc)\n",
    "\n",
    "\n",
    "def find_optimal_offset(projections, angles, detector_x_offsets, detector_y_offsets, stageoffset=0, searchrange=70):\n",
    "    ''' This function takes quite a while, which can probably be optimized.\n",
    "    On the other hand, we only have to do this once per scan setup, and then store the value for later use.\n",
    "    '''\n",
    "    projection0 = projections[0, :, :]\n",
    "    projection180 = np.flip(projections[round(projections.shape[0]/2)-1, :, :], 1)\n",
    "    print(detector_x_offsets[0], detector_x_offsets[round(projections.shape[0]/2)-1])\n",
    "    print(detector_y_offsets[0], detector_y_offsets[round(projections.shape[0]/2)-1])\n",
    "\n",
    "    shift, error, diffphase = phase_cross_correlation(projection0, projection180,\n",
    "                                                      upsample_factor=100)\n",
    "\n",
    "    estimate = -shift.item(1)/2\n",
    "    # print(estimate)\n",
    "    # estimate = 2.18\n",
    "    geosmall = ConeGeometryJasper(high_quality=False)\n",
    "    # we should avoid pixels from the cross of the detector\n",
    "    yshift = 3\n",
    "    # we also need to take into account that detector motion up to 5 pixesl could have been used during the acquisition\n",
    "    projections_small = projections[:, int(\n",
    "        projections.shape[1]/2)-6-yshift:int(projections.shape[1]/2)+5-yshift, :]\n",
    "\n",
    "    maxvalue = -9999\n",
    "    opt_shift = -99\n",
    "    cnt = 0\n",
    "    xvalues = []\n",
    "    yvalues = []\n",
    "    for i in range(int(estimate*100)-searchrange, int(estimate*100)+searchrange, 1):\n",
    "        # note that the detector x and y axis are opposite the x and y coordinate system of the geometry\n",
    "        geosmall.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+(i/100)*0.055)).T\n",
    "        geosmall.rotDetector = np.array((math.radians(-0.23), 0.0, 0.0))\n",
    "        geosmall.DSD = 192.57\n",
    "    #     stageoffset = 0\n",
    "        geosmall.DSO = geosmall.DSD-43.74 - stageoffset\n",
    "\n",
    "        imgfdk = algs.fdk(projections_small, geosmall, angles)\n",
    "        im = imgfdk[0, :, :].astype(np.float32)\n",
    "        dft = cv2.dft(im, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "        dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "        magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))\n",
    "        value = np.mean(magnitude_spectrum)\n",
    "        if value > maxvalue:\n",
    "            maxvalue = value\n",
    "            optshift = i\n",
    "        xvalues.append((i/100)*0.055)\n",
    "        yvalues.append(value)\n",
    "    plt.scatter(xvalues, yvalues)\n",
    "    return (optshift/100)*0.055\n",
    "\n",
    "\n",
    "def recon_scan(projections, angles, sample_z_offset, detector_x_offsets, detector_y_offsets, global_detector_shift_y):\n",
    "    geo = ConeGeometryJasper(high_quality=True)\n",
    "    geo.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+global_detector_shift_y)).T\n",
    "    # geo.rotDetector = np.array((0.0,0.0,0.0))\n",
    "    geo.rotDetector = np.array((math.radians(-0.23), 0.0, 0.0))\n",
    "    geo.DSD = 192.57\n",
    "    geo.DSO = geo.DSD-43.74 - sample_z_offset\n",
    "\n",
    "    geo.nVoxel = np.array(gReconVoxels)             # number of voxels              (vx)\n",
    "    geo.sVoxel = np.array(gReconSize)          # total size of the image       (mm)\n",
    "    geo.dVoxel = geo.sVoxel/geo.nVoxel                 # size of each voxel            (mm)\n",
    "    geo.offOrigin = np.array((0, 0, 0))\n",
    "\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter=None)\n",
    "    imgfdk = algs.fdk(projections, geo, angles, filter='cosine')\n",
    "    imgfdk[imgfdk < 0] = 0\n",
    "    imgfdkint = (imgfdk*10000).astype(np.int32)\n",
    "\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 1, 2)\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 0, 2)\n",
    "    imgfdkint = np.flip(imgfdkint, 2)\n",
    "\n",
    "    return imgfdkint\n",
    "\n",
    "\n",
    "def recon_scan_cgls(projections, angles, sample_z_offset, detector_x_offsets, detector_y_offsets, global_detector_shift_y):\n",
    "    geo = ConeGeometryJasper(high_quality=True)\n",
    "    geo.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+global_detector_shift_y)).T\n",
    "    geo.rotDetector = np.array((math.radians(-0.23), 0.0, 0.0))\n",
    "    geo.DSD = 192.57\n",
    "    geo.DSO = geo.DSD-43.74 - sample_z_offset\n",
    "\n",
    "    geo.nVoxel = np.array(gReconVoxels)             # number of voxels              (vx)\n",
    "    geo.sVoxel = np.array(gReconSize)          # total size of the image       (mm)\n",
    "    geo.dVoxel = geo.sVoxel/geo.nVoxel                 # size of each voxel            (mm)\n",
    "    geo.offOrigin = np.array((0, 0, 0))\n",
    "    imgfdk = algs.cgls(projections, geo, angles, 60, init='FDK')\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter=None)\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter='cosine')\n",
    "    imgfdk[imgfdk < 0] = 0\n",
    "    imgfdkint = (imgfdk*10000).astype(np.int32)\n",
    "\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 1, 2)\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 0, 2)\n",
    "    imgfdkint = np.flip(imgfdkint, 2)\n",
    "\n",
    "    return imgfdkint\n",
    "\n",
    "\n",
    "def recon_scan_fista(projections, angles, sample_z_offset, detector_x_offsets, detector_y_offsets, global_detector_shift_y, hyper, tviter, tvlambda):\n",
    "    geo = ConeGeometryJasper(high_quality=True)\n",
    "    geo.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+global_detector_shift_y)).T\n",
    "    geo.rotDetector = np.array((math.radians(-0.23), 0.0, 0.0))\n",
    "    geo.DSD = 192.57\n",
    "    geo.DSO = geo.DSD-43.74 - sample_z_offset\n",
    "\n",
    "    geo.nVoxel = np.array(gReconVoxels)             # number of voxels              (vx)\n",
    "    geo.sVoxel = np.array(gReconSize)          # total size of the image       (mm)\n",
    "    geo.dVoxel = geo.sVoxel/geo.nVoxel                 # size of each voxel            (mm)\n",
    "    geo.offOrigin = np.array((0, 0, 0))\n",
    "    imgfdk = algs.fista(projections, geo, angles, 100, hyper=hyper,\n",
    "                        tviter=tviter, tvlambda=tvlambda)\n",
    "# )algs.cgls(projections, geo, angles, 60,init='FDK')\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter=None)\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter='cosine')\n",
    "    imgfdk[imgfdk < 0] = 0\n",
    "    imgfdkint = (imgfdk*10000).astype(np.int32)\n",
    "\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 1, 2)\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 0, 2)\n",
    "    imgfdkint = np.flip(imgfdkint, 2)\n",
    "\n",
    "    return imgfdkint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'f:\\\\'\n",
    "# basefolder = os.path.join(drive,'jasper','data','20220726_scanseries')\n",
    "basefolder = os.path.join(drive, 'jasper', 'data', '20220805_tumourWhateverBreast')\n",
    "basejsonfile = os.path.join(basefolder, 'scan_settings.json')\n",
    "resultsfolder = os.path.join(basefolder, 'results_open_after')\n",
    "if not os.path.exists(resultsfolder):\n",
    "    os.makedirs(resultsfolder)\n",
    "if os.path.exists(basejsonfile):\n",
    "    f = open(basejsonfile)\n",
    "    dashboard = json.load(f)\n",
    "    spectralprojs_th0 = []\n",
    "    spectralopen_th0 = []\n",
    "    spectralprojs_th1 = []\n",
    "    spectralopen_th1 = []\n",
    "    th0_list = []\n",
    "    exp_time = []\n",
    "    th1_list = []\n",
    "    th1_exp_time = []\n",
    "    for i in dashboard['thresholdscan']:\n",
    "        scanfolder = os.path.join(basefolder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "        scanjson = os.path.join(scanfolder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "        openimagefolder = os.path.join(\n",
    "            basefolder, dashboard['thresholdscan'][i]['openimagesfolder'])\n",
    "        openimagejson = os.path.join(\n",
    "            openimagefolder, dashboard['thresholdscan'][i]['openimages_json'])\n",
    "        folderstring = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "        th0keV = folderstring[0:folderstring.find('_')]\n",
    "        th1keV = folderstring[folderstring.find('_')+1:]\n",
    "        exp_time.append(filereader.get_exposure_time_projection(scanjson))\n",
    "        th0_list.append(float(th0keV))\n",
    "        th1_list.append(float(th1keV))\n",
    "\n",
    "        projs_th0 = filereader.projectionsloader(\n",
    "            scanjson, th0=True, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "        openimg_th0 = filereader.openimgloader(\n",
    "            openimagejson, th0=True, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "        projs_th1 = filereader.projectionsloader(\n",
    "            scanjson, th0=False, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "        openimg_th1 = filereader.openimgloader(\n",
    "            openimagejson, th0=False, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "        spectralprojs_th0.append(projs_th0)\n",
    "        spectralopen_th0.append(openimg_th0)\n",
    "        spectralprojs_th1.append(projs_th1)\n",
    "        spectralopen_th1.append(openimg_th1)\n",
    "        detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scanjson)\n",
    "        angles = filereader.get_proj_angles(scanjson)\n",
    "        z_offset = filereader.get_samplestage_z_offset(scanjson)\n",
    "    spectralprojs_th0 = np.asarray(spectralprojs_th0)\n",
    "    spectralopen_th0 = np.asarray(spectralopen_th0)\n",
    "    spectralprojs_th1 = np.asarray(spectralprojs_th1)\n",
    "    spectralopen_th1 = np.asarray(spectralopen_th1)\n",
    "    exp_time = np.asarray(exp_time)\n",
    "    th0_list = np.asarray(th0_list)\n",
    "    th1_list = np.asarray(th1_list)\n",
    "\n",
    "    np.save(os.path.join(resultsfolder, 'projs_stack_th0.npy'), spectralprojs_th0)\n",
    "    np.save(os.path.join(resultsfolder, 'open_stack_th0.npy'), spectralopen_th0)\n",
    "    np.save(os.path.join(resultsfolder, 'projs_stack_th1.npy'), spectralprojs_th1)\n",
    "    np.save(os.path.join(resultsfolder, 'open_stack_th1.npy'), spectralopen_th1)\n",
    "    np.save(os.path.join(resultsfolder, 'thlist_th0.npy'), th0_list)\n",
    "    np.save(os.path.join(resultsfolder, 'thlist_th1.npy'), th1_list)\n",
    "\n",
    "    # print(spectralprojs.shape, spectralopen.shape)\n",
    "    # out = np.load(os.path.join(basefolder,'Projections_fitted.npy'))\n",
    "    # openout = np.load(os.path.join(basefolder,'Projections_open_fitted.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'f:\\\\'\n",
    "# basefolder = os.path.join(drive,'jasper','data','20220726_scanseries')\n",
    "basefolder = os.path.join(drive, 'jasper', 'data', '20220812_BreastTissueFFPE')\n",
    "basejsonfile = os.path.join(basefolder, 'scan_settings.json')\n",
    "results_folder = os.path.join(basefolder, 'results_fillgap_test')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing numpy files, should take ~7.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 57.64it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Load tiff files, transform a bit and save to numpy files.\n",
    "Load the files if they exist already '''\n",
    "\n",
    "if os.path.exists(basejsonfile):\n",
    "    f = open(basejsonfile)\n",
    "    dashboard = json.load(f)\n",
    "    exp_time = []\n",
    "    th0_list = []\n",
    "    th1_list = []\n",
    "\n",
    "    numpy_output_files = ['projs_stack_th0', 'open_stack_th0',\n",
    "                          'projs_stack_th1', 'open_stack_th1', 'thlist_th0', 'thlist_th1']\n",
    "    if os.path.exists(os.path.join(results_folder, numpy_output_files[0]+'.npy')):\n",
    "        print('Loading existing numpy files, should take ~7.5 seconds')\n",
    "\n",
    "        spectral_projs_th0 = np.load(os.path.join(results_folder, numpy_output_files[0]+'.npy'))\n",
    "        spectralopen_th0 = np.load(os.path.join(results_folder, numpy_output_files[1]+'.npy'))\n",
    "        spectralprojs_th1 = np.load(os.path.join(results_folder, numpy_output_files[2]+'.npy'))\n",
    "        spectralopen_th1 = np.load(os.path.join(results_folder, numpy_output_files[3]+'.npy'))\n",
    "        th0_list = np.load(os.path.join(results_folder, numpy_output_files[4]+'.npy'))\n",
    "        th1_list = np.load(os.path.join(results_folder, numpy_output_files[5]+'.npy'))\n",
    "\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scanfolder = os.path.join(basefolder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scanjson = os.path.join(scanfolder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            openimagefolder = scanfolder\n",
    "            openimagejson = scanjson\n",
    "            folderstring = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            \n",
    "            th0keV = folderstring[0:folderstring.find('_')]\n",
    "            th1keV = folderstring[folderstring.find('_')+1:]\n",
    "\n",
    "            angles = filereader.get_proj_angles(scanjson)\n",
    "            z_offset = filereader.get_samplestage_z_offset(scanjson)\n",
    "            detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scanjson)\n",
    "            exp_time.append(filereader.get_exposure_time_projection(scanjson))\n",
    "        exp_time = np.asarray(exp_time)\n",
    "\n",
    "    else:\n",
    "        print('Making new numpy files, should take ~4-5 minutes')\n",
    "        \n",
    "        spectral_projs_th0 = []\n",
    "        spectralopen_th0 = []\n",
    "        spectralprojs_th1 = []\n",
    "        spectralopen_th1 = []\n",
    "        th0_list = []\n",
    "        th1_list = []\n",
    "        th1_exp_time = []\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scanfolder = os.path.join(\n",
    "                basefolder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scanjson = os.path.join(scanfolder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            openimagefolder = scanfolder\n",
    "            openimagejson = scanjson\n",
    "            folderstring = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            th0keV = folderstring[0:folderstring.find('_')]\n",
    "            th1keV = folderstring[folderstring.find('_')+1:]\n",
    "            exp_time.append(filereader.get_exposure_time_projection(scanjson))\n",
    "            th0_list.append(float(th0keV))\n",
    "            th1_list.append(float(th1keV))\n",
    "\n",
    "            projs_th0 = filereader.projectionsloader(\n",
    "                scanjson, th0=True, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "            openimg_th0 = filereader.openimgloader(\n",
    "                openimagejson, th0=True, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "            projs_th1 = filereader.projectionsloader(\n",
    "                scanjson, th0=False, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "            openimg_th1 = filereader.openimgloader(\n",
    "                openimagejson, th0=False, badpixelcorr=gBadPixelCorrection, medianfilter=gMedianfilter, fillgap=gFillgap)\n",
    "            spectral_projs_th0.append(projs_th0)\n",
    "            spectralopen_th0.append(openimg_th0)\n",
    "            spectralprojs_th1.append(projs_th1)\n",
    "            spectralopen_th1.append(openimg_th1)\n",
    "            detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scanjson)\n",
    "            angles = filereader.get_proj_angles(scanjson)\n",
    "            z_offset = filereader.get_samplestage_z_offset(scanjson)\n",
    "        spectral_projs_th0 = np.asarray(spectral_projs_th0)\n",
    "        spectralopen_th0 = np.asarray(spectralopen_th0)\n",
    "        spectralprojs_th1 = np.asarray(spectralprojs_th1)\n",
    "        spectralopen_th1 = np.asarray(spectralopen_th1)\n",
    "        exp_time = np.asarray(exp_time)\n",
    "        th0_list = np.asarray(th0_list)\n",
    "        th1_list = np.asarray(th1_list)\n",
    "\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th0.npy'), spectral_projs_th0)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th0.npy'), spectralopen_th0)\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th1.npy'), spectralprojs_th1)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th1.npy'), spectralopen_th1)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th0.npy'), th0_list)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th1.npy'), th1_list)\n",
    "\n",
    "        # print(spectralprojs.shape, spectralopen.shape)\n",
    "        # out = np.load(os.path.join(basefolder,'Projections_fitted.npy'))\n",
    "        # openout = np.load(os.path.join(basefolder,'Projections_open_fitted.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 720, 512, 512)\n",
      "[-0.      0.1125 -0.225   0.05   -0.      0.1125  0.1625  0.225  -0.225\n",
      " -0.1125 -0.      0.05    0.05    0.05   -0.225   0.1625 -0.1125 -0.\n",
      " -0.1625 -0.05    0.1625 -0.1625 -0.1125 -0.      0.225  -0.      0.225\n",
      "  0.05   -0.      0.1625  0.05   -0.1125 -0.225  -0.      0.05   -0.05\n",
      "  0.225   0.05    0.1625  0.1625 -0.1625  0.05    0.1625 -0.05   -0.1625\n",
      "  0.225   0.1125 -0.225  -0.05    0.1625  0.05   -0.1125 -0.1125 -0.1125\n",
      "  0.225  -0.1625 -0.      0.1625 -0.1125  0.1625 -0.225  -0.05   -0.05\n",
      " -0.1125 -0.     -0.1625  0.225   0.1625 -0.05    0.1125 -0.1125  0.1625\n",
      " -0.      0.1125 -0.     -0.1625  0.1125 -0.     -0.     -0.05    0.225\n",
      " -0.1625 -0.05    0.225  -0.      0.1125 -0.1625  0.225   0.1125 -0.05\n",
      "  0.1625  0.225  -0.1625  0.1125  0.05   -0.05   -0.1625  0.05   -0.1125\n",
      "  0.05    0.225  -0.1625 -0.05   -0.1125 -0.225  -0.05   -0.225  -0.1625\n",
      " -0.05   -0.1625  0.225  -0.     -0.225   0.225  -0.1625  0.05   -0.\n",
      " -0.1625 -0.      0.1625 -0.      0.1625 -0.1625 -0.1625 -0.      0.1625\n",
      " -0.225  -0.1125 -0.05   -0.225   0.225   0.1625  0.225  -0.1125 -0.1125\n",
      "  0.1625  0.1125 -0.     -0.     -0.1125 -0.      0.1625  0.225   0.05\n",
      " -0.1125 -0.1125  0.1625 -0.      0.1625  0.1625 -0.05    0.1625  0.1625\n",
      " -0.     -0.225   0.225  -0.05    0.1125 -0.1625  0.1625 -0.      0.1125\n",
      " -0.225  -0.05   -0.1125 -0.      0.225   0.1125 -0.225   0.1625 -0.\n",
      " -0.1125 -0.      0.05    0.1125 -0.05   -0.     -0.1125 -0.1625  0.1125\n",
      " -0.05   -0.1625 -0.05    0.225   0.1125 -0.      0.225  -0.05   -0.05\n",
      " -0.05   -0.1125 -0.225  -0.     -0.05    0.1625 -0.225   0.1125 -0.05\n",
      " -0.05    0.1625  0.225  -0.1125 -0.1625 -0.225  -0.225  -0.225  -0.1625\n",
      " -0.1125  0.225  -0.1625 -0.05   -0.1125 -0.1125 -0.225  -0.     -0.05\n",
      " -0.     -0.1625  0.1625 -0.225   0.1625 -0.05   -0.1125 -0.05   -0.1625\n",
      "  0.1625 -0.1625 -0.05   -0.1625  0.1625  0.225   0.225  -0.1125 -0.05\n",
      " -0.1125 -0.225  -0.05    0.1125 -0.1625 -0.1625  0.1625 -0.1625 -0.\n",
      "  0.1625  0.1125 -0.05   -0.1625 -0.1125 -0.1125 -0.05    0.05    0.225\n",
      "  0.1125 -0.05   -0.05    0.225   0.225   0.1125 -0.1625 -0.1125 -0.05\n",
      " -0.05   -0.1625  0.1625  0.05   -0.1125  0.1625 -0.     -0.      0.1625\n",
      " -0.1125 -0.      0.1625  0.1125 -0.1625 -0.1125  0.1125 -0.225   0.05\n",
      " -0.1625  0.1625 -0.05   -0.225  -0.225   0.225  -0.05    0.1125 -0.1625\n",
      " -0.1125 -0.225   0.1625  0.1625  0.225  -0.05   -0.225   0.1625  0.1125\n",
      "  0.1625 -0.05   -0.      0.1625  0.225   0.05    0.225  -0.1125 -0.1125\n",
      "  0.1625 -0.225   0.225   0.05   -0.05   -0.05    0.1125 -0.225   0.05\n",
      "  0.1125  0.225  -0.      0.225   0.05    0.1125  0.1125 -0.      0.1125\n",
      "  0.225  -0.05   -0.225   0.05   -0.225  -0.1625  0.1625  0.05   -0.\n",
      "  0.1625 -0.05    0.225   0.05   -0.1125  0.1625 -0.      0.1625  0.1625\n",
      " -0.      0.05    0.1625  0.1125  0.1625  0.1625 -0.05    0.1625 -0.225\n",
      " -0.1125 -0.225  -0.1625 -0.1125 -0.1625  0.225  -0.05    0.05   -0.\n",
      " -0.225   0.05   -0.225  -0.1625  0.1625  0.225  -0.05   -0.      0.1125\n",
      "  0.05    0.1125  0.1125  0.05   -0.     -0.225   0.225  -0.225   0.1125\n",
      " -0.225   0.1125 -0.1125 -0.225   0.225  -0.1125 -0.05   -0.1125 -0.1625\n",
      " -0.1125  0.1125 -0.225  -0.1625  0.1625  0.1125  0.1625 -0.1125 -0.\n",
      " -0.     -0.      0.1125  0.225  -0.05    0.05    0.05   -0.05   -0.1625\n",
      " -0.05   -0.     -0.1125  0.1125  0.1625 -0.225  -0.225   0.1125 -0.1125\n",
      " -0.05   -0.1625 -0.1125 -0.     -0.1625  0.1125  0.225  -0.     -0.05\n",
      "  0.05   -0.      0.1625 -0.1125 -0.225  -0.1125  0.225  -0.225  -0.\n",
      "  0.225  -0.1125  0.225  -0.1125  0.1125  0.1625  0.1125 -0.225   0.1625\n",
      " -0.05   -0.05   -0.      0.1125 -0.05   -0.1125  0.05    0.1625 -0.\n",
      "  0.225  -0.225  -0.      0.225  -0.1125 -0.05   -0.225   0.1125 -0.1125\n",
      " -0.1125  0.1125  0.1625  0.1625 -0.225   0.1125 -0.225   0.225  -0.05\n",
      " -0.05   -0.1625 -0.1625  0.1625  0.225   0.1625 -0.1625  0.1125 -0.225\n",
      " -0.1625  0.1625 -0.      0.05    0.1625  0.1625 -0.     -0.05    0.225\n",
      " -0.     -0.1625 -0.1125 -0.     -0.1625 -0.1625  0.1125 -0.1625  0.225\n",
      "  0.225   0.225  -0.1625  0.05    0.225   0.1125 -0.1125 -0.05   -0.225\n",
      " -0.1625 -0.1625 -0.      0.1125  0.05   -0.1125 -0.1625  0.1125 -0.\n",
      "  0.225   0.05   -0.1125  0.1625 -0.1625 -0.05   -0.1625 -0.1125  0.225\n",
      "  0.1125 -0.1125 -0.1125  0.1625  0.05   -0.225  -0.225   0.1625 -0.05\n",
      "  0.1125  0.05   -0.1125 -0.05    0.225  -0.1625 -0.05   -0.225   0.225\n",
      " -0.      0.1125  0.05   -0.225  -0.     -0.225   0.225  -0.1625 -0.1125\n",
      " -0.1125  0.1625 -0.1625 -0.05    0.1625 -0.225   0.225   0.1625 -0.05\n",
      " -0.     -0.     -0.05    0.1625 -0.05   -0.1625  0.1625 -0.1125 -0.1625\n",
      "  0.1625 -0.     -0.     -0.05    0.05    0.05   -0.1625  0.1125  0.1125\n",
      " -0.05   -0.      0.225   0.1125  0.05   -0.225  -0.1625  0.225   0.05\n",
      " -0.     -0.05   -0.      0.225   0.225   0.225  -0.      0.1125 -0.1125\n",
      "  0.05   -0.     -0.1625  0.05    0.225   0.1125 -0.1125 -0.     -0.05\n",
      " -0.1125 -0.     -0.05    0.05    0.225  -0.1125 -0.     -0.1625 -0.05\n",
      " -0.05    0.1125  0.225  -0.      0.1125  0.225  -0.1625 -0.05   -0.1625\n",
      " -0.05    0.05   -0.     -0.     -0.      0.1625 -0.225  -0.1125 -0.05\n",
      "  0.225  -0.1625  0.05    0.1125 -0.1125  0.1625  0.05   -0.     -0.1125\n",
      "  0.1625 -0.     -0.     -0.225  -0.225   0.05   -0.1625 -0.1625 -0.225\n",
      " -0.1125  0.225  -0.      0.1625  0.225  -0.      0.05   -0.05    0.1625\n",
      " -0.1625 -0.05    0.225   0.1125  0.225   0.1625 -0.05   -0.1625  0.1625\n",
      " -0.      0.1625 -0.225   0.1125 -0.1625 -0.1625  0.1125 -0.1625 -0.\n",
      " -0.     -0.1625  0.225  -0.      0.1625 -0.225  -0.1125 -0.1125 -0.\n",
      "  0.1625  0.225  -0.1625 -0.225   0.1125 -0.05   -0.1625  0.05   -0.225\n",
      " -0.225  -0.1125  0.1625 -0.      0.225   0.1625  0.05   -0.1125 -0.225\n",
      " -0.     -0.225  -0.05   -0.225   0.1625  0.225  -0.1125 -0.1125 -0.1625\n",
      " -0.05   -0.     -0.1125 -0.225  -0.     -0.     -0.      0.1125  0.05  ]\n"
     ]
    }
   ],
   "source": [
    "print(spectral_projs_th0.shape)\n",
    "\n",
    "# global_detector_shift_y = find_optimal_offset(spectralprojs_th0[1,:,:,:],angles, detector_x_offsets,detector_y_offsets, stageoffset = 0, searchrange = 10)\n",
    "print(detector_y_offsets)\n",
    "# global_detector_shift_y=0.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 32, 512, 512)\n",
      "0 (9, 512, 512) 9\n",
      "th = 0, mean = 36895.64768079413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 91/512 [00:06<00:27, 15.40it/s]C:\\Users\\Medipix3_Bois\\AppData\\Local\\Temp\\ipykernel_65788\\1717289308.py:48: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  DAC_values[i, j] = DAC\n",
      "100%|██████████| 512/512 [00:33<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting polynomials... ~1 minute\n",
      "Calculating DACs...\n",
      "Calculating projection data...\n",
      "Saving Numpy array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Projections_th0_4.0_keV.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Medipix3_Bois\\AppData\\Local\\Temp\\ipykernel_65788\\1717289308.py:66: RuntimeWarning: invalid value encountered in log\n",
      "  ofc = -np.log(projection_data/mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Numpy array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\projs_th0_4.0OFC_interp.npy\n",
      "Doing median filter on OFC data...\n",
      "th = 0, finding optimal offset\n",
      "global_detector_shift_y = 25 (pixels ?)\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Proj_th0_4.0OFC_BPC_MF.nii\n",
      "Doing recon finally!\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Recon_th0_4.0OFC_BPC.nii\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Recon_th0_4.0OFC_BPC_MF.nii\n"
     ]
    }
   ],
   "source": [
    "def save_array(path: str, filename: str, array: np.ndarray, message:str=''):\n",
    "    s = os.path.join(path, filename)\n",
    "    \n",
    "    if (isinstance(array, np.ndarray)):\n",
    "        print(f'Saving Numpy array file: {s}')\n",
    "        np.save(s, array)\n",
    "    elif (isinstance(array, nib.Nifti1Image)):\n",
    "        print(f'Saving Nifti array file: {s}')\n",
    "        nib.save(array, s)\n",
    "    else:\n",
    "        print('Array type supported in save_array, add it!?')\n",
    "\n",
    "\n",
    "print(spectralopen_th0.shape)  # E.g. (9, 32, 512, 512)\n",
    "\n",
    "open_mean_th0 = np.mean(spectralopen_th0, axis=1)\n",
    "openmean_th1 = np.mean(spectralopen_th1, axis=1)\n",
    "\n",
    "for i in range(0, 1):\n",
    "    # openmean_th0.shape[0] was causing trouble...\n",
    "    print(i, open_mean_th0.shape, open_mean_th0.shape[0])  # E.g. 0 (9, 512, 512) 9\n",
    "    open_mean_th0[i, :, :] = open_mean_th0[i, :, :]/exp_time[i]\n",
    "    openmean_th1[i, :, :] = openmean_th1[i, :, :]/exp_time[i]\n",
    "\n",
    "for i in range(0, 1):\n",
    "    # spectralprojs_th0.shape[0] was causing trouble...\n",
    "    spectral_projs_th0[i, :, :, :] = spectral_projs_th0[i, :, :, :]/exp_time[i]\n",
    "    spectralprojs_th1[i, :, :, :] = spectralprojs_th1[i, :, :, :]/exp_time[i]\n",
    "\n",
    "# global_detector_shift_y = -0.31872500000000004\n",
    "gReconVoxels = (600, 600, 600)     # number of voxels              (vx)\n",
    "gReconSize = (15, 15, 15)          # total size of the image       (mm)\n",
    "# for th0 in range(0,openmean_th0.shape[0]):\n",
    "for th in range(0, 1):\n",
    "    mean = 0.25*(np.mean(open_mean_th0[th, 0:255, 0:255]) + np.mean(open_mean_th0[th, 0:255, 257:512]) + np.mean(\n",
    "        open_mean_th0[th, 257:512, 0:255]) + np.mean(open_mean_th0[th, 257:512, 257:512]))\n",
    "    print(f'th = {th}, mean = {mean}')  # E.g. 36895.64768079413\n",
    "    regression_out = np.zeros((3, 512, 512))\n",
    "    DAC_values = np.zeros((512, 512))\n",
    "    for i in trange(0, open_mean_th0.shape[1]):\n",
    "        for j in range(0, open_mean_th0.shape[2]):\n",
    "            yvalues = open_mean_th0[:, i, j]\n",
    "            regressions, res, _, _, _ = np.polyfit(th0_list, yvalues, 2, full=True)\n",
    "            regression_out[:, i, j] = regressions\n",
    "            DAC = solve_for_y(regressions, mean)[1]\n",
    "            if (DAC > th0_list[th]*2) or (DAC < th0_list[th]/2):\n",
    "                DAC = th0_list[th]\n",
    "            DAC_values[i, j] = DAC\n",
    "    \n",
    "    fit_array = spectral_projs_th0.reshape(spectral_projs_th0.shape[0], -1)\n",
    "\n",
    "    print('Fitting polynomials... ~1 minute')\n",
    "    regressions, res, _, _, _ = np.polyfit(th0_list, fit_array, 2, full=True)\n",
    "\n",
    "    print('Calculating DACs...')\n",
    "    calc_dacs = np.repeat(DAC_values[np.newaxis, :, :], spectral_projs_th0.shape[1], axis=0).flatten()\n",
    "\n",
    "    print('Calculating projection data...')\n",
    "    proj_data_flat = (regressions[0, :]*calc_dacs**2) + \\\n",
    "        (regressions[1, :]*calc_dacs**1) + regressions[2, :]\n",
    "    projection_data = proj_data_flat.reshape(\n",
    "        spectral_projs_th0.shape[1], spectral_projs_th0.shape[2], spectral_projs_th0.shape[3])\n",
    "    save_array(results_folder, 'Projections_th0_' + str(th0_list[th])+'_keV.npy', projection_data)\n",
    "    \n",
    "    mean = (np.mean(projection_data[:, :, 0:10]) + np.mean(projection_data[:, :, 503:513]))/2\n",
    "    ofc = -np.log(projection_data/mean)\n",
    "    save_array(results_folder, 'projs_th0_'+str(th0_list[th])+'OFC_interp.npy', ofc)\n",
    "\n",
    "    print('Doing median filter on OFC data...')\n",
    "    ofc_mf = filereader.median_filter_projection_set(ofc, 5)\n",
    "    diff_mf = np.abs(ofc-ofc_mf)\n",
    "    meanmap = np.mean(diff_mf, axis=0)\n",
    "    stdmap = np.std(diff_mf, axis=0)\n",
    "    badmap = np.ones((512, 512))\n",
    "    half = np.int32(badmap.shape[0]/2)\n",
    "    badmap[half-2:half+1] = 0\n",
    "    badmap[:, half-2:half+1] = 0\n",
    "    badmap[meanmap > 0.2] = 0\n",
    "    badmap[stdmap > 0.05] = 0\n",
    "    ofc_bpc = filereader.apply_badmap_to_projections(ofc, badmap)\n",
    "    ofc_bpc_mf = filereader.median_filter_projection_set(ofc_bpc, 3)\n",
    "    if th == 0:\n",
    "        print(f'th = {th}, finding optimal offset')\n",
    "        global_detector_shift_y = 25 #find_optimal_offset(spectral_projs_th0[1, :, :, :], angles, detector_x_offsets, detector_y_offsets, stageoffset=0, searchrange=25)\n",
    "        print(f'global_detector_shift_y = {global_detector_shift_y} (mm)')\n",
    "        \n",
    "        ni_img = nib.Nifti1Image(ofc_bpc_mf, np.eye(4))\n",
    "        save_array(results_folder, 'Proj_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n",
    "    \n",
    "    print('Doing recon finally!')\n",
    "    img_th0 = recon_scan(ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, global_detector_shift_y)\n",
    "    \n",
    "    ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "    save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC.nii', ni_img)\n",
    "\n",
    "    img_th0 = recon_scan(ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, global_detector_shift_y)\n",
    "    ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "    save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th = 0, finding optimal offset\n",
      "global_detector_shift_y = 0.2 (mm)\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Proj_th0_4.0OFC_BPC_MF.nii\n",
      "Doing recon finally!\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Recon_th0_4.0OFC_BPC.nii\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220812_BreastTissueFFPE\\results_fillgap_test\\Recon_th0_4.0OFC_BPC_MF.nii\n"
     ]
    }
   ],
   "source": [
    "print(f'th = {th}, finding optimal offset')\n",
    "global_detector_shift_y = .2 #find_optimal_offset(spectral_projs_th0[1, :, :, :], angles, detector_x_offsets, detector_y_offsets, stageoffset=0, searchrange=25)\n",
    "print(f'global_detector_shift_y = {global_detector_shift_y} (mm)')\n",
    "\n",
    "ni_img = nib.Nifti1Image(ofc_bpc_mf, np.eye(4))\n",
    "save_array(results_folder, 'Proj_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n",
    "\n",
    "print('Doing recon finally!')\n",
    "img_th0 = recon_scan(ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                    detector_y_offsets, global_detector_shift_y)\n",
    "\n",
    "ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC.nii', ni_img)\n",
    "\n",
    "img_th0 = recon_scan(ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                    detector_y_offsets, global_detector_shift_y)\n",
    "ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th1 in range(0, openmean_th1.shape[0]):\n",
    "    mean = 0.25*(np.mean(openmean_th1[th1, 0:255, 0:255]) + np.mean(openmean_th1[th1, 0:255, 257:512]) + np.mean(\n",
    "        openmean_th1[th1, 257:512, 0:255]) + np.mean(openmean_th1[th1, 257:512, 257:512]))\n",
    "    print(mean)\n",
    "    regression_out = np.zeros((3, 512, 512))\n",
    "    DACvalues = np.zeros((512, 512))\n",
    "    for i in range(0, openmean_th1.shape[1]):\n",
    "        for j in range(0, openmean_th1.shape[2]):\n",
    "            yvalues = openmean_th1[:, i, j]\n",
    "            regressions, res, _, _, _ = np.polyfit(th1_list, yvalues, 2, full=True)\n",
    "            regression_out[:, i, j] = regressions\n",
    "            DAC = solve_for_y(regressions, mean)[1]\n",
    "            if (DAC > th1_list[th1]*2) or (DAC < th1_list[th1]/2):\n",
    "                DAC = th1_list[th1]\n",
    "            DACvalues[i, j] = DAC\n",
    "    fitarray = spectralprojs_th1.reshape(spectralprojs_th1.shape[0], -1)\n",
    "    regressions, res, _, _, _ = np.polyfit(th1_list, fitarray, 2, full=True)\n",
    "    calcdacs = np.repeat(DACvalues[np.newaxis, :, :], spectralprojs_th1.shape[1], axis=0).flatten()\n",
    "\n",
    "    projdataflat = (regressions[0, :]*calcdacs**2) + \\\n",
    "        (regressions[1, :]*calcdacs**1) + regressions[2, :]\n",
    "    projectiondata = projdataflat.reshape(\n",
    "        spectralprojs_th1.shape[1], spectralprojs_th1.shape[2], spectralprojs_th1.shape[3])\n",
    "    np.save(os.path.join(results_folder, 'Projections_th1_'\n",
    "            + str(th1_list[th1])+'_keV.npy'), projectiondata)\n",
    "\n",
    "    mean = (np.mean(projectiondata[:, :, 0:10]) + np.mean(projectiondata[:, :, 503:513]))/2\n",
    "    ofc = -np.log(projectiondata/mean)\n",
    "    ni_img = nib.Nifti1Image(ofc, np.eye(4))\n",
    "    np.save(os.path.join(results_folder, 'projs_th1_'+str(th1_list[th1])+'OFC_interp.npy'), ofc)\n",
    "    ofc_mf = filereader.median_filter_projection_set(ofc, 5)\n",
    "    diff_mf = np.abs(ofc-ofc_mf)\n",
    "    meanmap = np.mean(diff_mf, axis=0)\n",
    "    stdmap = np.std(diff_mf, axis=0)\n",
    "    badmap = np.ones((512, 512))\n",
    "    half = np.int32(badmap.shape[0]/2)\n",
    "    badmap[half-2:half+1] = 0\n",
    "    badmap[:, half-2:half+1] = 0\n",
    "    badmap[meanmap > 0.2] = 0\n",
    "    badmap[stdmap > 0.05] = 0\n",
    "    ofc_bpc = filereader.apply_badmap_to_projections(ofc, badmap)\n",
    "    ofc_bpc_mf = filereader.median_filter_projection_set(ofc_bpc, 3)\n",
    "    img_th1 = recon_scan(ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, global_detector_shift_y)\n",
    "    ni_img = nib.Nifti1Image(img_th1, np.eye(4))\n",
    "    nib.save(ni_img, os.path.join(results_folder, 'Recon_th1_'+str(th1_list[th1])+'OFC_BPC.nii'))\n",
    "    img_th1 = recon_scan(ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, global_detector_shift_y)\n",
    "    ni_img = nib.Nifti1Image(img_th1, np.eye(4))\n",
    "    nib.save(ni_img, os.path.join(results_folder, 'Recon_th1_'+str(th1_list[th1])+'OFC_BPC_MF.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openmeansingle_th0 = np.mean(open_mean_th0, axis=(1, 2))\n",
    "openmeansingle_th1 = np.mean(openmean_th1, axis=(1, 2))\n",
    "plt.scatter(th0_list, openmeansingle_th0, label=\"th0\")\n",
    "plt.scatter(th1_list, openmeansingle_th1, label=\"th1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_detector_shift_y = 0.37565\n",
    "global_detector_shift_y = -0.31872500000000004\n",
    "\n",
    "hyperlist = [500]\n",
    "lambdalist = [0.010]\n",
    "for hyper in hyperlist:\n",
    "    for tvlambda in lambdalist:\n",
    "        # hyper=2.0e3\n",
    "        tviter = 100\n",
    "        # tvlambda=0.005\n",
    "        img_th0 = recon_scan_fista(ofc_2_mf.astype(np.float32), angles, z_offset, detector_x_offsets,\n",
    "                                   detector_y_offsets, global_detector_shift_y, hyper, tviter, tvlambda)\n",
    "        ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "        nib.save(ni_img, os.path.join(basefolder, 'recon_fista_mf_'\n",
    "                 + str(tviter) + '_' + str(hyper)+'_'+str(tvlambda) + '.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'f:\\\\'\n",
    "basefolder = os.path.join(drive, 'jasper', 'data', '20220603_RealTumor')\n",
    "basejsonfile = os.path.join(basefolder, 'scan_settings.json')\n",
    "\n",
    "if os.path.exists(basejsonfile):\n",
    "    f = open(basejsonfile)\n",
    "    dashboard = json.load(f)\n",
    "    for i in dashboard['thresholdscan']:\n",
    "        scanfolder = os.path.join(basefolder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "        scanjson = os.path.join(scanfolder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "        detector_x_offsets, detector_y_offsets = get_detector_offsets(scanjson)\n",
    "        angles = get_proj_angles(scanjson)\n",
    "        z_offset = get_samplestage_z_offset(scanjson)\n",
    "        projs_th0 = get_OFC_projections(scanjson, th0=True, UseOrig=False, ApplyLog=True)\n",
    "\n",
    "        # projectionsCorr = tomopy.prep.stripe.remove_all_stripe(projs_th0, snr=3, la_size=61, sm_size=21, dim=1, ncore=60, nchunk=None)\n",
    "        projectionsCorr = tomopy.prep.stripe.remove_stripe_fw(\n",
    "            projs_th0, level=None, wname='db5', sigma=0.2, pad=True, ncore=60, nchunk=None)\n",
    "        # global_detector_shift_y = find_optimal_offset(projs_th0, angles, detector_x_offsets, detector_y_offsets, z_offset)\n",
    "        global_detector_shift_y = 0.1915\n",
    "        gReconVoxels = (600, 512, 512)             # number of voxels              (vx)\n",
    "        gReconSize = (15, 12.8, 12.8)          # total size of the image       (mm)\n",
    "\n",
    "        img_th0 = recon_scan(projs_th0, angles, z_offset, detector_x_offsets,\n",
    "                             detector_y_offsets, global_detector_shift_y)\n",
    "        ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "        nib.save(ni_img, os.path.join(basefolder, 'recon_'+str(0)+'_th0_orig.nii'))\n",
    "        # imgfdk = tomopy.misc.corr.remove_ring(img_th0, center_x=None, center_y=None, thresh=1000.0, thresh_max=5000.0, thresh_min=10.0, theta_min=50, rwidth=10, int_mode='WRAP', ncore=60, nchunk=None, out=None)\n",
    "        # ni_img = nib.Nifti1Image(imgfdk, np.eye(4))\n",
    "        # nib.save(ni_img,  os.path.join(basefolder,'recon_'+str(0)+'_th0_corr_pre_post.nii'))\n",
    "        img_th0 = recon_scan(projectionsCorr, angles, z_offset, detector_x_offsets,\n",
    "                             detector_y_offsets, global_detector_shift_y)\n",
    "        ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "        nib.save(ni_img, os.path.join(basefolder, 'recon_'+str(0)+'_th0_corr2.nii'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tigre_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66dc09042d9756116a25f03fcdcbecfad5d8ca475bfcd3f7380c2109576abe38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
