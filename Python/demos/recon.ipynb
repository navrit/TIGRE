{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixels': 512, 'pixel_pitch': 0.055, 'fill_gap': True, 'median_filter': False, 'bad_pixel_correction': True, 'recon_voxels': (512, 512, 512), 'recon_size': (28.16, 28.16, 28.16), 'distance_source_detector': 188.347, 'z_stage_distance_mm': 20.0, 'distance_object_detector': 60.347, 'detector_rotation': (-0.005235987755982988, 0.0, 0.0)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Windows: Open Anaconda prompt\n",
    "conda create --name tigre_env -c anaconda -c ccpi -c conda-forge  python tigre simpleitk ipykernel opencv astropy tomopy nibabel scikit-image scikit-learn scipy tqdm scikit-learn-intelex jupyter ipywidgets\n",
    "conda activate tigre_env\n",
    "\n",
    "conda list --export > conda-package-list.txt\n",
    "conda create -n tigre_env --file conda-package-list.txt\n",
    "'''\n",
    "\n",
    "import json\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import tomopy\n",
    "from astropy.convolution import Gaussian2DKernel, interpolate_replace_nans\n",
    "from PIL import Image\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.signal import medfilt2d\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from tqdm import trange, tqdm\n",
    "from typing import List\n",
    "\n",
    "import tigre\n",
    "import tigre.algorithms as algs\n",
    "from tigre.utilities.geometry import Geometry\n",
    "\n",
    "import shared_functions as s\n",
    "\n",
    "kernel = Gaussian2DKernel(x_stddev=2)\n",
    "\n",
    "drive = 'f:\\\\'\n",
    "# basefolder = os.path.join(drive,'jasper','data','20220726_scanseries')\n",
    "# base_folder = os.path.join(drive, 'jasper', 'data', '20220812_BreastTissueFFPE')\n",
    "base_folder = os.path.join(drive, 'jasper', 'data', '20220819_ffpe_WhateverBreast')\n",
    "base_json_file = os.path.join(base_folder, 'scan_settings.json')\n",
    "results_folder = os.path.join(base_folder, 'results_fillgap')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "\n",
    "# TODO Read whatever numbers possible from the relevant json file\n",
    "'''\n",
    "+ Open base_folder/Scan_settings.json\n",
    "+ Get first key/value pair\n",
    "+ Open the folder+filename from that pair\n",
    "+ Get sample_z from that\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Make a list of globals for the reconstruction setting, and log them in a json file\n",
    "gReconParams = dict()\n",
    "\n",
    "gReconParams['pixels'] = 512  # (pixels)\n",
    "gReconParams['pixel_pitch'] = 0.055  # (mm)\n",
    "gReconParams['fill_gap'] = True\n",
    "gReconParams['median_filter'] = False\n",
    "gReconParams['bad_pixel_correction'] = True\n",
    "gReconParams['recon_voxels'] = (\n",
    "    gReconParams['pixels'], gReconParams['pixels'], gReconParams['pixels'])  # number of voxels (vx)\n",
    "gReconParams['recon_size'] = (gReconParams['pixels'] * gReconParams['pixel_pitch'], gReconParams['pixels']\n",
    "                                * gReconParams['pixel_pitch'], gReconParams['pixels'] * gReconParams['pixel_pitch'])  # (mm)\n",
    "\n",
    "''' TODO These should really be read from the JSON file! '''\n",
    "gReconParams['distance_source_detector'] = 188.347  # 9+9+30+100+30+9+1.347 (mm)\n",
    "gReconParams['z_stage_distance_mm'] = s.get_sample_z_from_first_scan_json(base_json_file) # Varies between 0 and 100 mm\n",
    "gReconParams['distance_object_detector'] = 30 + \\\n",
    "    gReconParams['z_stage_distance_mm'] + 9+1.347  # (mm)\n",
    "gReconParams['detector_rotation'] = (math.radians(-0.3), 0., 0.)  # (mm)\n",
    "\n",
    "assert gReconParams['z_stage_distance_mm'] < 100 and gReconParams['z_stage_distance_mm'] > 0\n",
    "\n",
    "print(gReconParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing numpy files, should take ~7.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 23.79it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(base_json_file):\n",
    "    f = open(base_json_file)\n",
    "    dashboard = json.load(f)\n",
    "    exp_time = []\n",
    "    th0_list = []\n",
    "    th1_list = []\n",
    "\n",
    "    numpy_output_files = ['projs_stack_th0.npy', 'open_stack_th0.npy',\n",
    "                          'projs_stack_th1.npy', 'open_stack_th1.npy', 'thlist_th0.npy', 'thlist_th1.npy']\n",
    "    if s.files_exist(results_folder, numpy_output_files):\n",
    "        print('Loading existing numpy files, should take ~7.5 seconds')\n",
    "\n",
    "        spectral_projs_th0 = np.load(os.path.join(results_folder, numpy_output_files[0]))\n",
    "        spectral_open_th0 = np.load(os.path.join(results_folder, numpy_output_files[1]))\n",
    "        spectral_projs_th1 = np.load(os.path.join(results_folder, numpy_output_files[2]))\n",
    "        spectral_open_th1 = np.load(os.path.join(results_folder, numpy_output_files[3]))\n",
    "        th0_list = np.load(os.path.join(results_folder, numpy_output_files[4]))\n",
    "        th1_list = np.load(os.path.join(results_folder, numpy_output_files[5]))\n",
    "\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scan_folder = os.path.join(base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scan_json = os.path.join(scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            open_image_folder = scan_folder\n",
    "            open_image_json = scan_json\n",
    "            folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            \n",
    "            th0_keV = folder_string[0:folder_string.find('_')]\n",
    "            th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "\n",
    "            angles = s.get_proj_angles(scan_json)\n",
    "            z_offset = s.get_samplestage_z_offset(scan_json)\n",
    "            detector_x_offsets, detector_y_offsets = s.get_detector_offsets(scan_json)\n",
    "            exp_time.append(s.get_exposure_time_projection(scan_json))\n",
    "        exp_time = np.asarray(exp_time)\n",
    "\n",
    "    else:\n",
    "        print(f'Making new numpy files, should take ~4.5 minutes. At least one file was missing :( ')\n",
    "        \n",
    "        spectral_projs_th0 = []\n",
    "        spectral_open_th0 = []\n",
    "        spectral_projs_th1 = []\n",
    "        spectral_open_th1 = []\n",
    "        th0_list = []\n",
    "        th1_list = []\n",
    "        th1_exp_time = []\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scan_folder = os.path.join(\n",
    "                base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scan_json = os.path.join(scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            open_image_folder = scan_folder\n",
    "            open_image_json = scan_json\n",
    "            folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            th0_keV = folder_string[0:folder_string.find('_')]\n",
    "            th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "            exp_time.append(s.get_exposure_time_projection(scan_json))\n",
    "            th0_list.append(float(th0_keV))\n",
    "            th1_list.append(float(th1_keV))\n",
    "\n",
    "            projs_th0 = s.projectionsloader(\n",
    "                scan_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            openimg_th0 = s.openimgloader(\n",
    "                open_image_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            projs_th1 = s.projectionsloader(\n",
    "                scan_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            openimg_th1 = s.openimgloader(\n",
    "                open_image_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            spectral_projs_th0.append(projs_th0)\n",
    "            spectral_open_th0.append(openimg_th0)\n",
    "            spectral_projs_th1.append(projs_th1)\n",
    "            spectral_open_th1.append(openimg_th1)\n",
    "            detector_x_offsets, detector_y_offsets = s.get_detector_offsets(scan_json)\n",
    "            angles = s.get_proj_angles(scan_json)\n",
    "            z_offset = s.get_samplestage_z_offset(scan_json)\n",
    "        spectral_projs_th0 = np.asarray(spectral_projs_th0)\n",
    "        spectral_open_th0 = np.asarray(spectral_open_th0)\n",
    "        spectral_projs_th1 = np.asarray(spectral_projs_th1)\n",
    "        spectral_open_th1 = np.asarray(spectral_open_th1)\n",
    "        exp_time = np.asarray(exp_time)\n",
    "        th0_list = np.asarray(th0_list)\n",
    "        th1_list = np.asarray(th1_list)\n",
    "\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th0.npy'), spectral_projs_th0)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th0.npy'), spectral_open_th0)\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th1.npy'), spectral_projs_th1)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th1.npy'), spectral_open_th1)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th0.npy'), th0_list)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th1.npy'), th1_list)\n",
    "\n",
    "        # print(spectralprojs.shape, spectralopen.shape)\n",
    "        # out = np.load(os.path.join(basefolder,'Projections_fitted.npy'))\n",
    "        # openout = np.load(os.path.join(basefolder,'Projections_open_fitted.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(spectral_projs_th0.shape)\n",
    "\n",
    "# _global_detector_shift_y = s.find_optimal_offset(gReconParams, spectral_projs_th0[1, :, :, :], angles, detector_x_offsets, detector_y_offsets, stage_offset=0, search_range=20)\n",
    "# print(_global_detector_shift_y)\n",
    "# global_detector_shift_y=0.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 64, 512, 512)\n",
      "th = 0, mean = 30606.29922039497\n",
      "Finding best DAC values per pixel...\n",
      "Loading existing numpy file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\th0_dac_values.npy\n",
      "Fitting polynomials... ~1 minute\n",
      "Calculating DACs...\n",
      "Calculating projection data...\n",
      "Saving Numpy array file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\Projections_th0_5.0_keV.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Medipix3_Bois\\AppData\\Local\\Temp\\ipykernel_14968\\3775556671.py:55: RuntimeWarning: invalid value encountered in log\n",
      "  ofc = -np.log(projection_data/mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 512, 512)\n",
      "Saving Numpy array file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\projs_th0_5.0OFC_interp.npy\n",
      "Loading existing numpy file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\th0_bpc.npy\n",
      "th = 0, finding optimal offset\n",
      "global_detector_shift_y = 0.21 (mm)\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\Proj_th0_5.0OFC_BPC_MF.nii\n",
      "Doing recon finally!\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\Recon_th0_5.0OFC_BPC.nii\n",
      "Saving Nifti array file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\Recon_th0_5.0OFC_BPC_MF.nii\n",
      "th = 1, mean = 25198.978491218284\n",
      "Finding best DAC values per pixel...\n",
      "Loading existing numpy file: f:\\jasper\\data\\20220819_ffpe_WhateverBreast\\results_fillgap\\th1_dac_values.npy\n",
      "Fitting polynomials... ~1 minute\n",
      "Calculating DACs...\n",
      "Calculating projection data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Software\\Tigre\\Python\\demos\\recon.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m calc_dacs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(DAC_values[np\u001b[39m.\u001b[39mnewaxis, :, :], spectral_projs_th0\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCalculating projection data...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m proj_data_flat \u001b[39m=\u001b[39m (regressions[\u001b[39m0\u001b[39m, :]\u001b[39m*\u001b[39mcalc_dacs\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m+\u001b[39m \\\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     (regressions[\u001b[39m1\u001b[39;49m, :]\u001b[39m*\u001b[39;49mcalc_dacs\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m+\u001b[39m regressions[\u001b[39m2\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m projection_data \u001b[39m=\u001b[39m proj_data_flat\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     spectral_projs_th0\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], spectral_projs_th0\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], spectral_projs_th0\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Software/Tigre/Python/demos/recon.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m s\u001b[39m.\u001b[39msave_array(results_folder, \u001b[39m'\u001b[39m\u001b[39mProjections_th0_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(th0_list[th])\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_keV.npy\u001b[39m\u001b[39m'\u001b[39m, projection_data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(f'global_detector_shift_x = {global_detector_shift_x}')\n",
    "# print(f'global_detector_shift_y = {global_detector_shift_y}')\n",
    "print(spectral_open_th0.shape)  # E.g. (9, 32, 512, 512) (Thresholds, # of open images, pixels, pixels)\n",
    "\n",
    "open_mean_th0 = np.mean(spectral_open_th0, axis=1)\n",
    "open_mean_th1 = np.mean(spectral_open_th1, axis=1)\n",
    "\n",
    "for i in range(open_mean_th0.shape[0]):\n",
    "    # print(i, open_mean_th0.shape, open_mean_th0.shape[0])  # E.g. 0 (9, 512, 512) 9\n",
    "    open_mean_th0[i, :, :] = open_mean_th0[i, :, :]/exp_time[i]\n",
    "    open_mean_th1[i, :, :] = open_mean_th1[i, :, :]/exp_time[i]\n",
    "\n",
    "for i in range(spectral_projs_th0.shape[0]):\n",
    "    spectral_projs_th0[i, :, :, :] = spectral_projs_th0[i, :, :, :] / exp_time[i]\n",
    "    spectral_projs_th1[i, :, :, :] = spectral_projs_th1[i, :, :, :] / exp_time[i]\n",
    "\n",
    "# global_detector_shift_y = -0.31872500000000004\n",
    "\n",
    "for th in range(0, open_mean_th0.shape[0]):\n",
    "    a0 = 0\n",
    "    a1 = (gReconParams['pixels'] // 2) - 1 # 255 for 512 pixels\n",
    "    a2 = (gReconParams['pixels'] // 2) + 1 # 257 for 512 pixels\n",
    "    a3 = gReconParams['pixels']\n",
    "    mean = 0.25 * (\n",
    "            np.mean(open_mean_th0[th, a0:a1, a0:a1]) +\n",
    "            np.mean(open_mean_th0[th, a0:a1, a2:a3]) +\n",
    "            np.mean(open_mean_th0[th, a2:a3, a0:a1]) +\n",
    "            np.mean(open_mean_th0[th, a2:a3, a2:a3])\n",
    "    )\n",
    "    print(f'th = {th}, mean = {mean}')  # E.g. 36895.64768079413\n",
    "    regression_out = np.zeros((3, gReconParams['pixels'], gReconParams['pixels']))\n",
    "    DAC_values = np.zeros((gReconParams['pixels'], gReconParams['pixels']))\n",
    "\n",
    "    print('Finding best DAC values per pixel...')\n",
    "    DAC_values = s.save_and_or_load_npy_files(\n",
    "            results_folder, f'th{th}_dac_values.npy', lambda: s.generate_dac_values(gReconParams, open_mean_th0, th0_list, mean, th))\n",
    "    \n",
    "    fit_array = spectral_projs_th0.reshape(spectral_projs_th0.shape[0], -1)\n",
    "\n",
    "    print('Fitting polynomials... ~1 minute')\n",
    "    regressions, res, _, _, _ = np.polyfit(th0_list, fit_array, 2, full=True)\n",
    "\n",
    "    print('Calculating DACs...')\n",
    "    calc_dacs = np.repeat(DAC_values[np.newaxis, :, :], spectral_projs_th0.shape[1], axis=0).flatten()\n",
    "\n",
    "    print('Calculating projection data...')\n",
    "    proj_data_flat = (regressions[0, :]*calc_dacs**2) + \\\n",
    "        (regressions[1, :]*calc_dacs**1) + regressions[2, :]\n",
    "    projection_data = proj_data_flat.reshape(\n",
    "        spectral_projs_th0.shape[1], spectral_projs_th0.shape[2], spectral_projs_th0.shape[3])\n",
    "    s.save_array(results_folder, 'Projections_th0_' + str(th0_list[th])+'_keV.npy', projection_data)\n",
    "    \n",
    "    # TODO Ask Jasper about this VERY SUSPICIOUS CODE\n",
    "    mean = (np.mean(projection_data[:, :, 0:10]) + np.mean(projection_data[:, :, 503:513]))/2\n",
    "    ofc = -np.log(projection_data/mean)\n",
    "    print(ofc.shape)\n",
    "    s.save_array(results_folder, 'projs_th0_'+str(th0_list[th])+'OFC_interp.npy', ofc)\n",
    "\n",
    "    ofc_bpc = s.save_and_or_load_npy_files(\n",
    "            results_folder, f'th{th}_bpc.npy', lambda: s.generate_bad_pixel_corrected_array(ofc, gReconParams))\n",
    "    ofc_bpc_mf = s.median_filter_projection_set(ofc_bpc, 3)\n",
    "    if th == 0:\n",
    "        print(f'th = {th}, finding optimal offset')\n",
    "        \n",
    "        centre_of_rotation_offset_x_mm = 2.51  # s.find_optimal_offset(gReconParams, spectral_projs_th0[1, :, :, :], angles, detector_x_offsets, detector_y_offsets, stage_offset=0, search_range=25)\n",
    "        centre_of_rotation_offset_y_mm = 0\n",
    "        print(f'centre_of_rotation_offset_x_mm = {centre_of_rotation_offset_x_mm} (mm)')\n",
    "        print(f'centre_of_rotation_offset_y_mm = {centre_of_rotation_offset_y_mm} (mm)')\n",
    "        \n",
    "        ni_img = nib.Nifti1Image(ofc_bpc_mf, np.eye(4))\n",
    "        s.save_array(results_folder, 'Proj_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n",
    "    \n",
    "    print('Doing recon finally!')\n",
    "    img_th0 = s.recon_scan(gReconParams, ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, centre_of_rotation_offset_x_mm, centre_of_rotation_offset_y_mm)\n",
    "    \n",
    "    ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "    s.save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC.nii', ni_img)\n",
    "\n",
    "    img_th0 = s.recon_scan(gReconParams, ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, centre_of_rotation_offset_y_mm)\n",
    "    ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "    s.save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'th = {th}, finding optimal offset')\n",
    "global_detector_shift_y = .2 #find_optimal_offset(spectral_projs_th0[1, :, :, :], angles, detector_x_offsets, detector_y_offsets, stageoffset=0, searchrange=25)\n",
    "print(f'global_detector_shift_y = {global_detector_shift_y} (mm)')\n",
    "\n",
    "ni_img = nib.Nifti1Image(ofc_bpc_mf, np.eye(4))\n",
    "s.save_array(results_folder, 'Proj_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n",
    "\n",
    "print('Doing recon finally!')\n",
    "img_th0 = s.recon_scan(gReconParams, ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                    detector_y_offsets, global_detector_shift_y)\n",
    "\n",
    "ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "s.save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC.nii', ni_img)\n",
    "\n",
    "img_th0 = s.recon_scan(gReconParams, ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                    detector_y_offsets, global_detector_shift_y)\n",
    "ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "s.save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th1 in range(0, open_mean_th1.shape[0]):\n",
    "    mean = 0.25*(np.mean(open_mean_th1[th1, 0:255, 0:255]) + np.mean(open_mean_th1[th1, 0:255, 257:512]) + np.mean(\n",
    "        open_mean_th1[th1, 257:512, 0:255]) + np.mean(open_mean_th1[th1, 257:512, 257:512]))\n",
    "    print(mean)\n",
    "    regression_out = np.zeros((3, 512, 512))\n",
    "    DACvalues = np.zeros((512, 512))\n",
    "    for i in range(0, open_mean_th1.shape[1]):\n",
    "        for j in range(0, open_mean_th1.shape[2]):\n",
    "            yvalues = open_mean_th1[:, i, j]\n",
    "            regressions, res, _, _, _ = np.polyfit(th1_list, yvalues, 2, full=True)\n",
    "            regression_out[:, i, j] = regressions\n",
    "            DAC = s.solve_for_y(regressions, mean)[1]\n",
    "            if (DAC > th1_list[th1]*2) or (DAC < th1_list[th1]/2):\n",
    "                DAC = th1_list[th1]\n",
    "            DACvalues[i, j] = DAC\n",
    "    fitarray = spectral_projs_th1.reshape(spectral_projs_th1.shape[0], -1)\n",
    "    regressions, res, _, _, _ = np.polyfit(th1_list, fitarray, 2, full=True)\n",
    "    calcdacs = np.repeat(DACvalues[np.newaxis, :, :], spectral_projs_th1.shape[1], axis=0).flatten()\n",
    "\n",
    "    projdataflat = (regressions[0, :]*calcdacs**2) + \\\n",
    "        (regressions[1, :]*calcdacs**1) + regressions[2, :]\n",
    "    projectiondata = projdataflat.reshape(\n",
    "        spectral_projs_th1.shape[1], spectral_projs_th1.shape[2], spectral_projs_th1.shape[3])\n",
    "    np.save(os.path.join(results_folder, 'Projections_th1_'\n",
    "            + str(th1_list[th1])+'_keV.npy'), projectiondata)\n",
    "\n",
    "    mean = (np.mean(projectiondata[:, :, 0:10]) + np.mean(projectiondata[:, :, 503:513]))/2\n",
    "    ofc = -np.log(projectiondata/mean)\n",
    "    ni_img = nib.Nifti1Image(ofc, np.eye(4))\n",
    "    np.save(os.path.join(results_folder, 'projs_th1_'+str(th1_list[th1])+'OFC_interp.npy'), ofc)\n",
    "    ofc_mf = s.median_filter_projection_set(ofc, 5)\n",
    "    diff_mf = np.abs(ofc-ofc_mf)\n",
    "    meanmap = np.mean(diff_mf, axis=0)\n",
    "    stdmap = np.std(diff_mf, axis=0)\n",
    "    badmap = np.ones((512, 512))\n",
    "    half = np.int32(badmap.shape[0]/2)\n",
    "    badmap[half-2:half+1] = 0\n",
    "    badmap[:, half-2:half+1] = 0\n",
    "    badmap[meanmap > 0.2] = 0\n",
    "    badmap[stdmap > 0.05] = 0\n",
    "    ofc_bpc = s.apply_badmap_to_projections(ofc, badmap)\n",
    "    ofc_bpc_mf = s.median_filter_projection_set(ofc_bpc, 3)\n",
    "    img_th1 = s.recon_scan(ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, global_detector_shift_y)\n",
    "    ni_img = nib.Nifti1Image(img_th1, np.eye(4))\n",
    "    nib.save(ni_img, os.path.join(results_folder, 'Recon_th1_'+str(th1_list[th1])+'OFC_BPC.nii'))\n",
    "    img_th1 = s.recon_scan(ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                         detector_y_offsets, global_detector_shift_y)\n",
    "    ni_img = nib.Nifti1Image(img_th1, np.eye(4))\n",
    "    nib.save(ni_img, os.path.join(results_folder, 'Recon_th1_'+str(th1_list[th1])+'OFC_BPC_MF.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openmeansingle_th0 = np.mean(open_mean_th0, axis=(1, 2))\n",
    "openmeansingle_th1 = np.mean(open_mean_th1, axis=(1, 2))\n",
    "plt.scatter(th0_list, openmeansingle_th0, label=\"th0\")\n",
    "plt.scatter(th1_list, openmeansingle_th1, label=\"th1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_detector_shift_y = 0.37565\n",
    "global_detector_shift_y = -0.31872500000000004\n",
    "\n",
    "hyperlist = [500]\n",
    "lambdalist = [0.010]\n",
    "for hyper in hyperlist:\n",
    "    for tvlambda in lambdalist:\n",
    "        # hyper=2.0e3\n",
    "        tviter = 100\n",
    "        # tvlambda=0.005\n",
    "        img_th0 = s.recon_scan_fista(ofc_2_mf.astype(np.float32), angles, z_offset, detector_x_offsets,\n",
    "                                   detector_y_offsets, global_detector_shift_y, hyper, tviter, tvlambda)\n",
    "        ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "        nib.save(ni_img, os.path.join(base_folder, 'recon_fista_mf_'\n",
    "                 + str(tviter) + '_' + str(hyper)+'_'+str(tvlambda) + '.nii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'f:\\\\'\n",
    "# basefolder = os.path.join(drive,'jasper','data','20220726_scanseries')\n",
    "base_folder = os.path.join(drive, 'jasper', 'data', '20220805_tumourWhateverBreast')\n",
    "base_json_file = os.path.join(base_folder, 'scan_settings.json')\n",
    "results_folder = os.path.join(base_folder, 'results_open_after')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "if os.path.exists(base_json_file):\n",
    "    f = open(base_json_file)\n",
    "    dashboard = json.load(f)\n",
    "    spectral_projs_th0 = []\n",
    "    spectral_open_th0 = []\n",
    "    spectral_projs_th1 = []\n",
    "    spectral_open_th1 = []\n",
    "    th0_list = []\n",
    "    exp_time = []\n",
    "    th1_list = []\n",
    "    th1_exp_time = []\n",
    "    for i in dashboard['thresholdscan']:\n",
    "        scan_folder = os.path.join(base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "        scan_json = os.path.join(scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "        open_image_folder = os.path.join(\n",
    "            base_folder, dashboard['thresholdscan'][i]['openimagesfolder'])\n",
    "        open_image_json = os.path.join(\n",
    "            open_image_folder, dashboard['thresholdscan'][i]['openimages_json'])\n",
    "        folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "        th0_keV = folder_string[0:folder_string.find('_')]\n",
    "        th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "        exp_time.append(s.get_exposure_time_projection(scan_json))\n",
    "        th0_list.append(float(th0_keV))\n",
    "        th1_list.append(float(th1_keV))\n",
    "\n",
    "        projs_th0 = s.projectionsloader(\n",
    "            scan_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "        openimg_th0 = s.openimgloader(\n",
    "            open_image_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "        projs_th1 = s.projectionsloader(\n",
    "            scan_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "        openimg_th1 = s.openimgloader(\n",
    "            open_image_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "        spectral_projs_th0.append(projs_th0)\n",
    "        spectral_open_th0.append(openimg_th0)\n",
    "        spectral_projs_th1.append(projs_th1)\n",
    "        spectral_open_th1.append(openimg_th1)\n",
    "        detector_x_offsets, detector_y_offsets = s.get_detector_offsets(scan_json)\n",
    "        angles = s.get_proj_angles(scan_json)\n",
    "        z_offset = s.get_samplestage_z_offset(scan_json)\n",
    "    spectral_projs_th0 = np.asarray(spectral_projs_th0)\n",
    "    spectral_open_th0 = np.asarray(spectral_open_th0)\n",
    "    spectral_projs_th1 = np.asarray(spectral_projs_th1)\n",
    "    spectral_open_th1 = np.asarray(spectral_open_th1)\n",
    "    exp_time = np.asarray(exp_time)\n",
    "    th0_list = np.asarray(th0_list)\n",
    "    th1_list = np.asarray(th1_list)\n",
    "\n",
    "    np.save(os.path.join(results_folder, 'projs_stack_th0.npy'), spectral_projs_th0)\n",
    "    np.save(os.path.join(results_folder, 'open_stack_th0.npy'), spectral_open_th0)\n",
    "    np.save(os.path.join(results_folder, 'projs_stack_th1.npy'), spectral_projs_th1)\n",
    "    np.save(os.path.join(results_folder, 'open_stack_th1.npy'), spectral_open_th1)\n",
    "    np.save(os.path.join(results_folder, 'thlist_th0.npy'), th0_list)\n",
    "    np.save(os.path.join(results_folder, 'thlist_th1.npy'), th1_list)\n",
    "\n",
    "    # print(spectralprojs.shape, spectralopen.shape)\n",
    "    # out = np.load(os.path.join(basefolder,'Projections_fitted.npy'))\n",
    "    # openout = np.load(os.path.join(basefolder,'Projections_open_fitted.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'f:\\\\'\n",
    "basefolder = os.path.join(drive, 'jasper', 'data', '20220603_RealTumor')\n",
    "basejsonfile = os.path.join(basefolder, 'scan_settings.json')\n",
    "\n",
    "if os.path.exists(basejsonfile):\n",
    "    f = open(basejsonfile)\n",
    "    dashboard = json.load(f)\n",
    "    for i in dashboard['thresholdscan']:\n",
    "        scanfolder = os.path.join(basefolder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "        scanjson = os.path.join(scanfolder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "        detector_x_offsets, detector_y_offsets = s.get_detector_offsets(scanjson)\n",
    "        angles = s.get_proj_angles(scanjson)\n",
    "        z_offset = s.get_samplestage_z_offset(scanjson)\n",
    "        projs_th0 = s.get_OFC_projections(scanjson, th0=True, UseOrig=False, ApplyLog=True)\n",
    "\n",
    "        # projectionsCorr = tomopy.prep.stripe.remove_all_stripe(projs_th0, snr=3, la_size=61, sm_size=21, dim=1, ncore=60, nchunk=None)\n",
    "        projectionsCorr = tomopy.prep.stripe.remove_stripe_fw(\n",
    "            projs_th0, level=None, wname='db5', sigma=0.2, pad=True, ncore=60, nchunk=None)\n",
    "        # global_detector_shift_y = find_optimal_offset(projs_th0, angles, detector_x_offsets, detector_y_offsets, z_offset)\n",
    "        global_detector_shift_y = 0.1915\n",
    "        gReconVoxels = (600, 512, 512)             # number of voxels              (vx)\n",
    "        gReconSize = (15, 12.8, 12.8)          # total size of the image       (mm)\n",
    "\n",
    "        img_th0 = s.recon_scan(projs_th0, angles, z_offset, detector_x_offsets,\n",
    "                             detector_y_offsets, global_detector_shift_y)\n",
    "        ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "        nib.save(ni_img, os.path.join(basefolder, 'recon_'+str(0)+'_th0_orig.nii'))\n",
    "        # imgfdk = tomopy.misc.corr.remove_ring(img_th0, center_x=None, center_y=None, thresh=1000.0, thresh_max=5000.0, thresh_min=10.0, theta_min=50, rwidth=10, int_mode='WRAP', ncore=60, nchunk=None, out=None)\n",
    "        # ni_img = nib.Nifti1Image(imgfdk, np.eye(4))\n",
    "        # nib.save(ni_img,  os.path.join(basefolder,'recon_'+str(0)+'_th0_corr_pre_post.nii'))\n",
    "        img_th0 = s.recon_scan(projectionsCorr, angles, z_offset, detector_x_offsets,\n",
    "                             detector_y_offsets, global_detector_shift_y)\n",
    "        ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "        nib.save(ni_img, os.path.join(basefolder, 'recon_'+str(0)+'_th0_corr2.nii'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tigre_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66dc09042d9756116a25f03fcdcbecfad5d8ca475bfcd3f7380c2109576abe38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
