{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "'''\n",
    "Windows: Open Anaconda prompt\n",
    "conda create --name tigre_env -c anaconda -c ccpi -c conda-forge  python tigre simpleitk ipykernel opencv astropy tomopy nibabel scikit-image scikit-learn scipy tqdm scikit-learn-intelex jupyter ipywidgets\n",
    "conda activate tigre_env\n",
    "\n",
    "conda list --export > conda-package-list.txt\n",
    "conda create -n tigre_env --file conda-package-list.txt\n",
    "'''\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from re import L\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "# from __future__ import division\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from tqdm import trange, tqdm\n",
    "from typing import List\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "import tigre.algorithms as algs\n",
    "from tigre.utilities.geometry import Geometry\n",
    "\n",
    "import filereader\n",
    "\n",
    "kernel = Gaussian2DKernel(x_stddev=2)\n",
    "\n",
    "\n",
    "class ConeGeometryJasper(Geometry):\n",
    "    ''' Some of these parameters are overwritten with better values in the recon_scan functions '''\n",
    "\n",
    "    def __init__(self, gReconParams: dict, high_quality: bool = True, nVoxel=None):\n",
    "\n",
    "        Geometry.__init__(self)\n",
    "        pixels = gReconParams['pixels']\n",
    "        pixel_pitch_mm = gReconParams['pixel_pitch']\n",
    "        DSD = gReconParams['distance_source_detector']\n",
    "        DOD = gReconParams['distance_object_detector']\n",
    "        rotDetector = gReconParams['detector_rotation']\n",
    "\n",
    "        total_detector_size_mm = pixels * pixel_pitch_mm\n",
    "\n",
    "        # VARIABLE                                                DESCRIPTION                   UNITS\n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        if high_quality:\n",
    "            self.nDetector = np.array((pixels, pixels))         # number of pixels              (px)\n",
    "            self.nVoxel = np.array((pixels, pixels, pixels))    # number of voxels              (vx)\n",
    "            self.sVoxel = np.array((total_detector_size_mm,\n",
    "                                    total_detector_size_mm,\n",
    "                                    total_detector_size_mm))    # total size of the image       (mm)\n",
    "        else:\n",
    "            number_of_voxels = 1\n",
    "            number_of_pixels = 11\n",
    "\n",
    "            self.nDetector = np.array((number_of_pixels,\n",
    "                                       pixels))                # number of pixels              (px)\n",
    "            self.nVoxel = np.array((number_of_voxels,\n",
    "                                    pixels,\n",
    "                                    pixels))                    # number of voxels              (vx)\n",
    "            self.sVoxel = np.array((pixel_pitch_mm,\n",
    "                                    pixels * pixel_pitch_mm,\n",
    "                                    pixels * pixel_pitch_mm))    # total size of the image       (mm)\n",
    "\n",
    "        ''' We will set the common variables last because other variables depend on some of them '''\n",
    "        # VARIABLE                                                DESCRIPTION                   UNITS\n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        self.DSD = DSD                                          # Distance Source Detector      (mm)\n",
    "        self.DSO = DSD - DOD                                    # Distance Source Origin        (mm)\n",
    "        # Detector parameters\n",
    "        self.dDetector = np.array((pixel_pitch_mm,\n",
    "                                   pixel_pitch_mm))             # size of each pixel            (mm)\n",
    "        self.sDetector = self.nDetector * self.dDetector        # total size of the detector    (mm)\n",
    "\n",
    "        # Offsets\n",
    "        # Offset of image from origin   (mm)\n",
    "        self.offOrigin = np.array((0, 0, 0))\n",
    "        self.offDetector = np.array((0, 0))                     # Offset of Detector            (mm)\n",
    "        # Detector rotation             (radians)\n",
    "        self.rotDetector = rotDetector\n",
    "        # Image parameters\n",
    "        self.dVoxel = self.sVoxel / self.nVoxel                 # size of each voxel            (mm)\n",
    "        # Auxiliary\n",
    "        # Accuracy of FWD proj          (vx/sample)\n",
    "        self.accuracy = 0.5\n",
    "        # Mode\n",
    "        self.mode = 'cone'                                      # parallel, cone                ...\n",
    "        self.filter = None\n",
    "\n",
    "        '''if nVoxel is not None:\n",
    "            self.DSD = 1536                                     # Distance Source Detector      (mm)\n",
    "            self.DSO = 1000                                     # Distance Source Origin        (mm)\n",
    "                                                                # Detector parameters\n",
    "            self.nDetector = np.array((nVoxel[1],\n",
    "                                       nVoxel[2])\n",
    "                                                                ) # (V,U) number of pixels        (px)\n",
    "            self.dDetector = np.array([0.8, 0.8])               # size of each pixel            (mm)\n",
    "            self.sDetector = self.dDetector * self.nDetector    # total size of the detector    (mm)\n",
    "                                                                # Image parameters\n",
    "            self.nVoxel = np.array((nVoxel))                    # number of voxels              (vx)\n",
    "            self.sVoxel = np.array((256, 256, 256))             # total size of the image       (mm)\n",
    "            self.dVoxel = self.sVoxel / self.nVoxel             # size of each voxel            (mm)\n",
    "            # Offsets\n",
    "            self.offOrigin = np.array((0, 0, 0))                # Offset of image from origin   (mm)\n",
    "            self.offDetector = np.array((0, 0))                 # Offset of Detector            (mm)\n",
    "            self.rotDetector = np.array((0, 0, 0))\n",
    "            # Auxiliary\n",
    "            # Accuracy of FWD proj          (vx/sample)\n",
    "            self.accuracy = 0.5\n",
    "            # Mode\n",
    "            self.mode = 'cone'                                  # parallel, cone'''\n",
    "\n",
    "\n",
    "def solve_for_y(poly_coeffs, y):\n",
    "    pc = poly_coeffs.copy()\n",
    "    pc[-1] -= y\n",
    "    return np.roots(pc)\n",
    "\n",
    "\n",
    "def find_optimal_offset(gReconParams: dict, projections, angles, detector_x_offsets, detector_y_offsets, stage_offset=0, search_range=70):\n",
    "    ''' TODO Replace this! It does not work\n",
    "\n",
    "    This function takes quite a while, which can probably be optimized.\n",
    "    On the other hand, we only have to do this once per scan setup, and then store the value for later use.\n",
    "    '''\n",
    "\n",
    "    projection0 = projections[0, :, :]\n",
    "    projection180 = np.flip(projections[round(projections.shape[0]/2)-1, :, :], 1)\n",
    "\n",
    "    shift, error, diffphase = phase_cross_correlation(projection0, projection180,\n",
    "                                                      upsample_factor=100)\n",
    "\n",
    "    estimate = -shift.item(1)/2\n",
    "    print(estimate)\n",
    "    #########################################\n",
    "    # estimate = 4.9 # px\n",
    "    ##########################################\n",
    "\n",
    "    geom = ConeGeometryJasper(gReconParams, high_quality=False)\n",
    "    # we should avoid pixels from the cross of the detector\n",
    "    yshift = 3\n",
    "    # we also need to take into account that detector motion up to 5 pixels could have been used during the acquisition\n",
    "    projections_small = projections[:, int(\n",
    "        projections.shape[1]/2)-6-yshift:int(projections.shape[1]/2)+5-yshift, :]\n",
    "\n",
    "    max_value = -9999\n",
    "    opt_shift = -99\n",
    "    cnt = 0\n",
    "    xvalues = []\n",
    "    yvalues = []\n",
    "\n",
    "    for i in trange(int(estimate*100) - search_range, int(estimate*100) + search_range, 1):\n",
    "        # note that the detector x and y axis are opposite the x and y coordinate system of the geometry\n",
    "        geom.offDetector = np.vstack(\n",
    "            (detector_y_offsets, detector_x_offsets+(i/100) * gReconParams['pixel_pitch'])).T\n",
    "        geom.rotDetector = np.array(gReconParams['detector_rotation'])\n",
    "        geom.DSD = gReconParams['distance_source_detector']\n",
    "        # stageoffset = 0\n",
    "        geom.DSO = geom.DSD - gReconParams['distance_object_detector']  # - stageoffset\n",
    "\n",
    "        imgfdk = algs.fdk(projections_small, geom, angles)\n",
    "        im = imgfdk[0, :, :].astype(np.float32)\n",
    "        dft = cv2.dft(im, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "        dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "        magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))\n",
    "        value = np.mean(magnitude_spectrum)\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            opt_shift = i\n",
    "        xvalues.append((i/100) * gReconParams['pixel_pitch'])\n",
    "        yvalues.append(value)\n",
    "\n",
    "    plt.xlabel('X values')\n",
    "    plt.ylabel('Y values')\n",
    "    plt.scatter(xvalues, yvalues)\n",
    "    plt.show()\n",
    "    return (opt_shift/100) * gReconParams['pixel_pitch']\n",
    "\n",
    "\n",
    "def recon_scan(gReconParams: dict, projections, angles, sample_z_offset, detector_x_offsets, detector_y_offsets, global_detector_shift_y, high_quality=True):\n",
    "    geo = ConeGeometryJasper(gReconParams, high_quality=high_quality)\n",
    "    geo.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+global_detector_shift_y)).T\n",
    "    geo.rotDetector = np.array(gReconParams['detector_rotation'])\n",
    "    geo.DSD = gReconParams['distance_source_detector']\n",
    "    geo.DSO = geo.DSD - gReconParams['distance_object_detector'] - sample_z_offset\n",
    "\n",
    "    # number of voxels              (vx)\n",
    "    geo.nVoxel = np.array(gReconParams['recon_voxels'])\n",
    "    geo.sVoxel = np.array(gReconParams['recon_size'])          # total size of the image       (mm)\n",
    "    geo.dVoxel = geo.sVoxel/geo.nVoxel                 # size of each voxel            (mm)\n",
    "    geo.offOrigin = np.array((0, 0, 0))\n",
    "\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter=None)\n",
    "    imgfdk = algs.fdk(projections, geo, angles, filter='cosine')\n",
    "    imgfdk[imgfdk < 0] = 0\n",
    "    imgfdkint = (imgfdk*10000).astype(np.int32)\n",
    "\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 1, 2)\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 0, 2)\n",
    "    imgfdkint = np.flip(imgfdkint, 2)\n",
    "\n",
    "    return imgfdkint\n",
    "\n",
    "\n",
    "def recon_scan_cgls(gReconParams: dict, projections, angles, sample_z_offset, detector_x_offsets, detector_y_offsets, global_detector_shift_y, high_quality=True):\n",
    "    geo = ConeGeometryJasper(gReconParams, high_quality=high_quality)\n",
    "    geo.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+global_detector_shift_y)).T\n",
    "    geo.rotDetector = np.array(gReconParams['detector_rotation'])\n",
    "    geo.DSD = gReconParams['distance_source_detector']\n",
    "    geo.DSO = geo.DSD - gReconParams['distance_object_detector'] - sample_z_offset\n",
    "\n",
    "    # number of voxels              (vx)\n",
    "    geo.nVoxel = np.array(gReconParams['recon_voxels'])\n",
    "    geo.sVoxel = np.array(gReconParams['recon_size'])          # total size of the image       (mm)\n",
    "    geo.dVoxel = geo.sVoxel/geo.nVoxel                 # size of each voxel            (mm)\n",
    "    geo.offOrigin = np.array((0, 0, 0))\n",
    "    imgfdk = algs.cgls(projections, geo, angles, 60, init='FDK')\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter=None)\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter='cosine')\n",
    "    imgfdk[imgfdk < 0] = 0\n",
    "    imgfdkint = (imgfdk*10000).astype(np.int32)\n",
    "\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 1, 2)\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 0, 2)\n",
    "    imgfdkint = np.flip(imgfdkint, 2)\n",
    "\n",
    "    return imgfdkint\n",
    "\n",
    "\n",
    "def recon_scan_fista(gReconParams: dict, projections, angles, sample_z_offset, detector_x_offsets, detector_y_offsets, global_detector_shift_y, hyper, tviter, tvlambda, high_quality=True):\n",
    "    geo = ConeGeometryJasper(gReconParams, high_quality=high_quality)\n",
    "    geo.offDetector = np.vstack((detector_y_offsets, detector_x_offsets+global_detector_shift_y)).T\n",
    "    geo.rotDetector = np.array(gReconParams['detector_rotation'])\n",
    "    geo.DSD = gReconParams['distance_source_detector']\n",
    "    geo.DSO = geo.DSD - gReconParams['distance_object_detector'] - sample_z_offset\n",
    "\n",
    "    # number of voxels              (vx)\n",
    "    geo.nVoxel = np.array(gReconParams['recon_voxels'])\n",
    "    geo.sVoxel = np.array(gReconParams['recon_size'])          # total size of the image       (mm)\n",
    "    geo.dVoxel = geo.sVoxel/geo.nVoxel                 # size of each voxel            (mm)\n",
    "    geo.offOrigin = np.array((0, 0, 0))\n",
    "    imgfdk = algs.fista(projections, geo, angles, 100, hyper=hyper,\n",
    "                        tviter=tviter, tvlambda=tvlambda)\n",
    "# )algs.cgls(projections, geo, angles, 60,init='FDK')\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter=None)\n",
    "    # imgfdk=algs.fdk(projections,geo,angles,filter='cosine')\n",
    "    imgfdk[imgfdk < 0] = 0\n",
    "    imgfdkint = (imgfdk*10000).astype(np.int32)\n",
    "\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 1, 2)\n",
    "    imgfdkint = np.swapaxes(imgfdkint, 0, 2)\n",
    "    imgfdkint = np.flip(imgfdkint, 2)\n",
    "\n",
    "    return imgfdkint\n",
    "\n",
    "\n",
    "def save_array(path: str, filename: str, array: np.ndarray):\n",
    "    s = os.path.join(path, filename)\n",
    "\n",
    "    if (isinstance(array, np.ndarray)):\n",
    "        print(f'Saving Numpy array file: {s}')\n",
    "        np.save(s, array)\n",
    "    elif (isinstance(array, nib.Nifti1Image)):\n",
    "        print(f'Saving Nifti array file: {s}')\n",
    "        nib.save(array, s)\n",
    "    else:\n",
    "        print('Array type supported in save_array, add it!?')\n",
    "\n",
    "\n",
    "def files_exist(path: str, file_list: List[str]) -> bool:\n",
    "    ''' If a file does not exist or is less than the threshold, return False '''\n",
    "    for f in file_list:\n",
    "        full_path = os.path.join(path, f)\n",
    "        if not os.path.exists(full_path):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def save_and_or_load_npy_files(path: str, array_filename: str, generating_function):\n",
    "    p = os.path.join(path, array_filename)\n",
    "    if files_exist(path, array_filename):\n",
    "        print(f'Loading existing numpy file: {p}')\n",
    "        my_array = np.load()\n",
    "    else:\n",
    "        my_array = generating_function()\n",
    "        print(f'Saving numpy file: {p}')\n",
    "        np.save(p, my_array)\n",
    "    return my_array\n",
    "\n",
    "\n",
    "def generate_dac_values(gReconParams, open_mean_th0, th0_list, mean):\n",
    "    DAC_values = np.zeros((gReconParams['pixels'], gReconParams['pixels']))\n",
    "    for i in trange(0, open_mean_th0.shape[1]):\n",
    "        for j in range(0, open_mean_th0.shape[2]):\n",
    "            yvalues = open_mean_th0[:, i, j]\n",
    "            regressions, res, _, _, _ = np.polyfit(th0_list, yvalues, 2, full=True)\n",
    "            regression_out[:, i, j] = regressions\n",
    "            DAC = solve_for_y(regressions, mean)[1]\n",
    "            if (DAC > th0_list[th]*2) or (DAC < th0_list[th]/2):\n",
    "                DAC = th0_list[th]\n",
    "            DAC_values[i, j] = DAC\n",
    "    return DAC_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of globals for the reconstruction setting, and log them in a json file\n",
    "gReconParams = dict()\n",
    "\n",
    "gReconParams['pixels'] = 512  # (pixels)\n",
    "gReconParams['pixel_pitch'] = 0.055  # (mm)\n",
    "gReconParams['fill_gap'] = True\n",
    "gReconParams['median_filter'] = False\n",
    "gReconParams['bad_pixel_correction'] = True\n",
    "gReconParams['recon_voxels'] = (gReconParams['pixels'], gReconParams['pixels'],\n",
    "                                gReconParams['pixels'])  # number of voxels (vx)\n",
    "gReconParams['recon_size'] = (gReconParams['pixels'] * gReconParams['pixel_pitch'], gReconParams['pixels']\n",
    "                                * gReconParams['pixel_pitch'], gReconParams['pixels'] * gReconParams['pixel_pitch'])  # (mm)\n",
    "\n",
    "''' TODO These should really be read from the JSON file! '''\n",
    "gReconParams['distance_source_detector'] = 188.347  # 9+9+30+100+30+9+1.347 (mm)\n",
    "gReconParams['z_stage_distance_mm'] = 20  # Varies between 0 and 100 mm\n",
    "gReconParams['distance_object_detector'] = 30 + \\\n",
    "    gReconParams['z_stage_distance_mm'] + 9+1.347  # (mm)\n",
    "gReconParams['detector_rotation'] = (\n",
    "    math.radians(-0.3), 0., 0.)  # (mm) TODO Check accuracy!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'f:\\\\'\n",
    "# basefolder = os.path.join(drive,'jasper','data','20220726_scanseries')\n",
    "base_folder = os.path.join(drive, 'jasper', 'data', '20220822_ffpe_WhateverBreast')\n",
    "# base_folder = os.path.join(drive, 'jasper', 'data', '20220822_Al_Phantom_Recon_Alignment')\n",
    "base_json_file = os.path.join(base_folder, 'scan_settings.json')\n",
    "results_folder = os.path.join(base_folder, 'results_fillgap')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing numpy files, should take ~7.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 47.58it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(base_json_file):\n",
    "    f = open(base_json_file)\n",
    "    dashboard = json.load(f)\n",
    "    exp_time = []\n",
    "    th0_list = []\n",
    "    th1_list = []\n",
    "\n",
    "    numpy_output_files = ['projs_stack_th0.npy', 'open_stack_th0.npy',\n",
    "                            'projs_stack_th1.npy', 'open_stack_th1.npy', 'thlist_th0.npy', 'thlist_th1.npy']\n",
    "    if files_exist(results_folder, numpy_output_files):\n",
    "        print('Loading existing numpy files, should take ~7.5 seconds')\n",
    "\n",
    "        spectral_projs_th0 = np.load(os.path.join(results_folder, numpy_output_files[0]))\n",
    "        spectral_open_th0 = np.load(os.path.join(results_folder, numpy_output_files[1]))\n",
    "        spectral_projs_th1 = np.load(os.path.join(results_folder, numpy_output_files[2]))\n",
    "        spectral_open_th1 = np.load(os.path.join(results_folder, numpy_output_files[3]))\n",
    "        th0_list = np.load(os.path.join(results_folder, numpy_output_files[4]))\n",
    "        th1_list = np.load(os.path.join(results_folder, numpy_output_files[5]))\n",
    "\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scan_folder = os.path.join(\n",
    "                base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scan_json = os.path.join(\n",
    "                scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            open_image_folder = scan_folder\n",
    "            open_image_json = scan_json\n",
    "            folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "\n",
    "            th0_keV = folder_string[0:folder_string.find('_')]\n",
    "            th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "\n",
    "            angles = filereader.get_proj_angles(scan_json)\n",
    "            z_offset = filereader.get_samplestage_z_offset(scan_json)\n",
    "            detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scan_json)\n",
    "            exp_time.append(filereader.get_exposure_time_projection(scan_json))\n",
    "        exp_time = np.asarray(exp_time)\n",
    "\n",
    "    else:\n",
    "        print(f'Making new numpy files, should take ~4.5 minutes. At least one file was missing :( ')\n",
    "\n",
    "        spectral_projs_th0 = []\n",
    "        spectral_open_th0 = []\n",
    "        spectral_projs_th1 = []\n",
    "        spectral_open_th1 = []\n",
    "        th0_list = []\n",
    "        th1_list = []\n",
    "        th1_exp_time = []\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scan_folder = os.path.join(\n",
    "                base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scan_json = os.path.join(\n",
    "                scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            open_image_folder = scan_folder\n",
    "            open_image_json = scan_json\n",
    "            folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            th0_keV = folder_string[0:folder_string.find('_')]\n",
    "            th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "            exp_time.append(filereader.get_exposure_time_projection(scan_json))\n",
    "            th0_list.append(float(th0_keV))\n",
    "            th1_list.append(float(th1_keV))\n",
    "\n",
    "            projs_th0 = filereader.projectionsloader(\n",
    "                scan_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            openimg_th0 = filereader.openimgloader(\n",
    "                open_image_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            projs_th1 = filereader.projectionsloader(\n",
    "                scan_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            openimg_th1 = filereader.openimgloader(\n",
    "                open_image_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            spectral_projs_th0.append(projs_th0)\n",
    "            spectral_open_th0.append(openimg_th0)\n",
    "            spectral_projs_th1.append(projs_th1)\n",
    "            spectral_open_th1.append(openimg_th1)\n",
    "            detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scan_json)\n",
    "            angles = filereader.get_proj_angles(scan_json)\n",
    "            z_offset = filereader.get_samplestage_z_offset(scan_json)\n",
    "        spectral_projs_th0 = np.asarray(spectral_projs_th0)\n",
    "        spectral_open_th0 = np.asarray(spectral_open_th0)\n",
    "        spectral_projs_th1 = np.asarray(spectral_projs_th1)\n",
    "        spectral_open_th1 = np.asarray(spectral_open_th1)\n",
    "        exp_time = np.asarray(exp_time)\n",
    "        th0_list = np.asarray(th0_list)\n",
    "        th1_list = np.asarray(th1_list)\n",
    "\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th0.npy'), spectral_projs_th0)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th0.npy'), spectral_open_th0)\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th1.npy'), spectral_projs_th1)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th1.npy'), spectral_open_th1)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th0.npy'), th0_list)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th1.npy'), th1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing numpy files, should take ~7.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 512, 512)\n",
      "th = 0, mean = 34693.714762393254\n",
      "Finding best DAC values per pixel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:30<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving numpy file: f:\\jasper\\data\\20220822_Al_Phantom_Recon_Alignment\\results_fillgap\\th0_dac_values.npy\n",
      "Fitting polynomials... ~1 minute\n",
      "Calculating DACs...\n",
      "Calculating projection data...\n",
      "Saving Numpy array file: f:\\jasper\\data\\20220822_Al_Phantom_Recon_Alignment\\results_fillgap\\Projections_th0_5.0_keV.npy\n",
      "Saving Numpy array file: f:\\jasper\\data\\20220822_Al_Phantom_Recon_Alignment\\results_fillgap\\projs_th0_5.0OFC_interp.npy\n",
      "Doing median filter on OFC data...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\ICR\\anaconda3\\envs\\EnvICR\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Software\\Tigre\\Python\\demos\\filereader.py\", line 236, in apply_badmap_to_projection\n    return it(list(np.ndindex(lproj.shape))).reshape(lproj.shape)\n  File \"c:\\Users\\ICR\\anaconda3\\envs\\EnvICR\\lib\\site-packages\\scipy\\interpolate\\ndgriddata.py\", line 112, in __call__\n    return self.values[i]\nIndexError: index 0 is out of bounds for axis 0 with size 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29888/3004129913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mbadmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeanmap\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mbadmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstdmap\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mofc_bpc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilereader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_badmap_to_projections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbadmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[0mofc_bpc_mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilereader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian_filter_projection_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofc_bpc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# TODO THIS IS FUCKED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Software\\Tigre\\Python\\demos\\filereader.py\u001b[0m in \u001b[0;36mapply_badmap_to_projections\u001b[1;34m(projections, badmap)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# for p in processes:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# print(p.get())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Software\\Tigre\\Python\\demos\\filereader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# for p in processes:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# print(p.get())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ICR\\anaconda3\\envs\\EnvICR\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "''' Load tiff files, transform a bit and save to numpy files.\n",
    "Load the files if they exist already '''\n",
    "\n",
    "\n",
    "def files_exist(path:str, file_list:List[str]) -> bool:\n",
    "    ''' If a file does not exist or is less than the threshold, return False '''\n",
    "    for f in file_list:\n",
    "        full_path = os.path.join(path, f)\n",
    "        if not os.path.exists(full_path):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "if os.path.exists(base_json_file):\n",
    "    f = open(base_json_file)\n",
    "    dashboard = json.load(f)\n",
    "    exp_time = []\n",
    "    th0_list = []\n",
    "    th1_list = []\n",
    "\n",
    "    numpy_output_files = ['projs_stack_th0.npy', 'open_stack_th0.npy',\n",
    "                          'projs_stack_th1.npy', 'open_stack_th1.npy', 'thlist_th0.npy', 'thlist_th1.npy']\n",
    "    if files_exist(results_folder, numpy_output_files):\n",
    "        print('Loading existing numpy files, should take ~7.5 seconds')\n",
    "\n",
    "        spectral_projs_th0 = np.load(os.path.join(results_folder, numpy_output_files[0]))\n",
    "        spectral_open_th0 = np.load(os.path.join(results_folder, numpy_output_files[1]))\n",
    "        spectral_projs_th1 = np.load(os.path.join(results_folder, numpy_output_files[2]))\n",
    "        spectral_open_th1 = np.load(os.path.join(results_folder, numpy_output_files[3]))\n",
    "        th0_list = np.load(os.path.join(results_folder, numpy_output_files[4]))\n",
    "        th1_list = np.load(os.path.join(results_folder, numpy_output_files[5]))\n",
    "\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scan_folder = os.path.join(base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scan_json = os.path.join(scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            open_image_folder = scan_folder\n",
    "            open_image_json = scan_json\n",
    "            folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            \n",
    "            th0_keV = folder_string[0:folder_string.find('_')]\n",
    "            th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "\n",
    "            angles = filereader.get_proj_angles(scan_json)\n",
    "            z_offset = filereader.get_samplestage_z_offset(scan_json)\n",
    "            detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scan_json)\n",
    "            exp_time.append(filereader.get_exposure_time_projection(scan_json))\n",
    "        exp_time = np.asarray(exp_time)\n",
    "\n",
    "    else:\n",
    "        print(f'Making new numpy files, should take ~4.5 minutes. At least one file was missing :( ')\n",
    "        \n",
    "        spectral_projs_th0 = []\n",
    "        spectral_open_th0 = []\n",
    "        spectral_projs_th1 = []\n",
    "        spectral_open_th1 = []\n",
    "        th0_list = []\n",
    "        th1_list = []\n",
    "        th1_exp_time = []\n",
    "        for i in tqdm(dashboard['thresholdscan']):\n",
    "            scan_folder = os.path.join(\n",
    "                base_folder, dashboard['thresholdscan'][i]['projectionsfolder'])\n",
    "            scan_json = os.path.join(scan_folder, dashboard['thresholdscan'][i]['projections_json'])\n",
    "            open_image_folder = scan_folder\n",
    "            open_image_json = scan_json\n",
    "            folder_string = dashboard['thresholdscan'][i]['projectionsfolder']\n",
    "            th0_keV = folder_string[0:folder_string.find('_')]\n",
    "            th1_keV = folder_string[folder_string.find('_')+1:]\n",
    "            exp_time.append(filereader.get_exposure_time_projection(scan_json))\n",
    "            th0_list.append(float(th0_keV))\n",
    "            th1_list.append(float(th1_keV))\n",
    "\n",
    "            projs_th0 = filereader.projectionsloader(\n",
    "                scan_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            openimg_th0 = filereader.openimgloader(\n",
    "                open_image_json, th0=True, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            projs_th1 = filereader.projectionsloader(\n",
    "                scan_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            openimg_th1 = filereader.openimgloader(\n",
    "                open_image_json, th0=False, badpixelcorr=gReconParams['bad_pixel_correction'], medianfilter=gReconParams['median_filter'], fillgap=gReconParams['fill_gap'])\n",
    "            spectral_projs_th0.append(projs_th0)\n",
    "            spectral_open_th0.append(openimg_th0)\n",
    "            spectral_projs_th1.append(projs_th1)\n",
    "            spectral_open_th1.append(openimg_th1)\n",
    "            detector_x_offsets, detector_y_offsets = filereader.get_detector_offsets(scan_json)\n",
    "            angles = filereader.get_proj_angles(scan_json)\n",
    "            z_offset = filereader.get_samplestage_z_offset(scan_json)\n",
    "        spectral_projs_th0 = np.asarray(spectral_projs_th0)\n",
    "        spectral_open_th0 = np.asarray(spectral_open_th0)\n",
    "        spectral_projs_th1 = np.asarray(spectral_projs_th1)\n",
    "        spectral_open_th1 = np.asarray(spectral_open_th1)\n",
    "        exp_time = np.asarray(exp_time)\n",
    "        th0_list = np.asarray(th0_list)\n",
    "        th1_list = np.asarray(th1_list)\n",
    "\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th0.npy'), spectral_projs_th0)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th0.npy'), spectral_open_th0)\n",
    "        np.save(os.path.join(results_folder, 'projs_stack_th1.npy'), spectral_projs_th1)\n",
    "        np.save(os.path.join(results_folder, 'open_stack_th1.npy'), spectral_open_th1)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th0.npy'), th0_list)\n",
    "        np.save(os.path.join(results_folder, 'thlist_th1.npy'), th1_list)\n",
    "\n",
    "        # print(spectralprojs.shape, spectralopen.shape)\n",
    "        # out = np.load(os.path.join(basefolder,'Projections_fitted.npy'))\n",
    "        # openout = np.load(os.path.join(basefolder,'Projections_open_fitted.npy'))\n",
    "\n",
    "print(spectral_open_th0.shape)\n",
    "\n",
    "open_mean_th0 = np.mean(spectral_open_th0, axis=1)\n",
    "open_mean_th1 = np.mean(spectral_open_th1, axis=1)\n",
    "\n",
    "for i in range(open_mean_th0.shape[0]):\n",
    "    # print(i, open_mean_th0.shape, open_mean_th0.shape[0])  # E.g. 0 (9, 512, 512) 9\n",
    "    open_mean_th0[i, :, :] = open_mean_th0[i, :, :]/exp_time[i]\n",
    "    open_mean_th1[i, :, :] = open_mean_th1[i, :, :]/exp_time[i]\n",
    "\n",
    "for i in range(spectral_projs_th0.shape[0]):\n",
    "    spectral_projs_th0[i, :, :, :] = spectral_projs_th0[i, :, :, :] / exp_time[i]\n",
    "    spectral_projs_th1[i, :, :, :] = spectral_projs_th1[i, :, :, :] / exp_time[i]\n",
    "\n",
    "# global_detector_shift_y = -0.31872500000000004\n",
    "\n",
    "for th in range(0, open_mean_th0.shape[0]):\n",
    "    a0 = 0\n",
    "    a1 = (gReconParams['pixels'] // 2) - 1  # 255 for 512 pixels\n",
    "    a2 = (gReconParams['pixels'] // 2) + 1  # 257 for 512 pixels\n",
    "    a3 = gReconParams['pixels']\n",
    "    mean = 0.25 * (\n",
    "        np.mean(open_mean_th0[th, a0:a1, a0:a1])\n",
    "        + np.mean(open_mean_th0[th, a0:a1, a2:a3])\n",
    "        + np.mean(open_mean_th0[th, a2:a3, a0:a1])\n",
    "        + np.mean(open_mean_th0[th, a2:a3, a2:a3])\n",
    "    )\n",
    "    print(f'th = {th}, mean = {mean}')  # E.g. 36895.64768079413\n",
    "    regression_out = np.zeros((3, gReconParams['pixels'], gReconParams['pixels']))\n",
    "\n",
    "    print('Finding best DAC values per pixel...')\n",
    "    DAC_values = save_and_or_load_npy_files(\n",
    "        results_folder, f'th{th}_dac_values.npy', lambda: generate_dac_values(gReconParams, open_mean_th0, th0_list, mean))\n",
    "\n",
    "    fit_array = spectral_projs_th0.reshape(spectral_projs_th0.shape[0], -1)\n",
    "\n",
    "    print('Fitting polynomials... ~1 minute')\n",
    "    regressions, _, _, _, _ = np.polyfit(th0_list, fit_array, 2, full=True)\n",
    "    # regressions = save_and_or_load_npy_files(results_folder, f'th{th}_regressions.npy', lambda: FILLMEIN(...))\n",
    "\n",
    "    print('Calculating DACs...')\n",
    "    calc_dacs = np.repeat(DAC_values[np.newaxis, :, :],\n",
    "                            spectral_projs_th0.shape[1], axis=0).flatten()\n",
    "\n",
    "    print('Calculating projection data...')\n",
    "    proj_data_flat = (regressions[0, :]*calc_dacs**2) + \\\n",
    "        (regressions[1, :]*calc_dacs**1) + regressions[2, :]\n",
    "    projection_data = proj_data_flat.reshape(\n",
    "        spectral_projs_th0.shape[1], spectral_projs_th0.shape[2], spectral_projs_th0.shape[3])\n",
    "    save_array(results_folder, 'Projections_th0_'\n",
    "                + str(th0_list[th])+'_keV.npy', projection_data)\n",
    "\n",
    "    # TODO Ask Jasper about this VERY SUSPICIOUS CODE\n",
    "    # mean = (np.mean(projection_data[:, :, 0:10]) + np.mean(projection_data[:, :, 503:513]))/2\n",
    "    ofc = -np.log(projection_data/1)\n",
    "    save_array(results_folder, 'projs_th0_'+str(th0_list[th])+'OFC_interp.npy', ofc)\n",
    "\n",
    "    print('Doing median filter on OFC data...')\n",
    "    ofc_mf = filereader.median_filter_projection_set(ofc, 5)\n",
    "    diff_mf = np.abs(ofc-ofc_mf)\n",
    "    meanmap = np.mean(diff_mf, axis=0)\n",
    "    stdmap = np.std(diff_mf, axis=0)\n",
    "    badmap = np.ones((gReconParams['pixels'], gReconParams['pixels']))\n",
    "    half = np.int32(badmap.shape[0]/2)\n",
    "    badmap[half-2:half+1] = 0\n",
    "    badmap[:, half-2:half+1] = 0\n",
    "    badmap[meanmap > 0.2] = 0\n",
    "    badmap[stdmap > 0.05] = 0\n",
    "    ofc_bpc = filereader.apply_badmap_to_projections(ofc, badmap)\n",
    "    ofc_bpc_mf = filereader.median_filter_projection_set(ofc_bpc, 3)  # TODO THIS IS FUCKED\n",
    "    if th == 0:\n",
    "        # print(f'th = {th}, finding optimal offset')\n",
    "        # (mm) # find_optimal_offset(gReconParams, spectral_projs_th0[1, :, :, :], angles, detector_x_offsets, detector_y_offsets, stage_offset=0, search_range=25)\n",
    "        global_detector_shift_y = 2.51\n",
    "        print(f'global_detector_shift_y = {global_detector_shift_y} (mm)')\n",
    "\n",
    "        ni_img = nib.Nifti1Image(ofc_bpc_mf, np.eye(4))\n",
    "        save_array(results_folder, 'Proj_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n",
    "\n",
    "    print('Doing recon finally!')\n",
    "    img_th0 = recon_scan(gReconParams, ofc_bpc, angles, z_offset, detector_x_offsets,\n",
    "                            detector_y_offsets, global_detector_shift_y)\n",
    "\n",
    "    ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "    save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC.nii', ni_img)\n",
    "\n",
    "    img_th0 = recon_scan(gReconParams, ofc_bpc_mf, angles, z_offset, detector_x_offsets,\n",
    "                            detector_y_offsets, global_detector_shift_y)\n",
    "    ni_img = nib.Nifti1Image(img_th0, np.eye(4))\n",
    "    save_array(results_folder, 'Recon_th0_'+str(th0_list[th])+'OFC_BPC_MF.nii', ni_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05e5e3a507181dd6fed8cc1ce074a835dab8e3c10b5dcb24bee281e62c05848b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
